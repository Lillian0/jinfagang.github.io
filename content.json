{"meta":{"title":"Jin Tian","subtitle":null,"description":"Just my blog","author":"Jintian","url":"http://yoursite.com"},"pages":[{"title":"Achievements","date":"2017-05-23T01:27:01.000Z","updated":"2017-05-23T01:27:01.000Z","comments":true,"path":"achievements/index.html","permalink":"http://yoursite.com/achievements/index.html","excerpt":"","text":"Welcome to my Achievements Wall Here I will show some interesting projects and my personal achievements No.5 Github OpenSource Project Trending Top 3 I place this into 5th position, because it is not good enough, I created it but not keep on that,this project - weibo_terminater, now on Githubhas 1499 stars, and so many people add my wechat to talk about their life :). It’s really interesting. No.4 Jarvis - Artificial Intelligence Assistant Ever HaveJarvis maybe that most significant things I have done. I finish build Jarvis on 2017-4-28, which takes me almost 5 weeks. I’d like to paste some chat screen shots. And you can find Jarvis via my wechat, Jarvis now have more important mission to do rather than gossip. The point is that, Jarvis can specific images!!"},{"title":"About","date":"2017-05-03T10:56:56.000Z","updated":"2017-05-03T10:56:56.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"金天清华大学在读研究生，深度学习领域研究者热爱人工智能，以及电子硬件制作，是要成为钢铁侠的男人欧曼信息科技有限公司CEO，业余魔术师微信：jintianiloveu"},{"title":"tags","date":"2016-10-25T11:28:20.000Z","updated":"2016-10-25T11:28:20.000Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"上天的步骤","slug":"上天的步骤","date":"2017-05-23T01:02:16.000Z","updated":"2017-05-23T01:11:17.000Z","comments":true,"path":"2017/05/23/上天的步骤/","link":"","permalink":"http://yoursite.com/2017/05/23/上天的步骤/","excerpt":"本文简要记录一下上天的步骤","text":"本文简要记录一下上天的步骤 首先是相关依赖的安装直接clone我的一件安装脚本，基本上所有软件都安装就绪。 设置nginxnginx设置最简单的就是http只写80端口，如果是https的话除了服务器的防火墙比较蛋疼外，还要加上证书，证书也得加载nginx里面，除了nginx，django的服务器也要加载证书，比较蛋疼。 一步一步测试可以先改nginx，然后django启动自带的简单服务器，或者开启gunicorn。 对了如果要添加一个下载链接，只需要在nginx中映射一下本地文件的路径即可。 设置superviosr设置supervisor就是设置gunicorn，一个意思，但是这里supervisor的配置文件的后罪名不要搞错了，这个都有模板的。然后就是sudo supervisorctl startsudo supervisorctl reloadsudo supervisorctl start all 配置数据库我一般工程里面的数据库用户名和密码比较简单，但是如果是实际场景这样可不行。配置数据库首先创建一个当前系统用户名的数据库用户：sudo -u postgres createuser --superuser rootsudo -u postgres psql# 进入控制台设置刚才创建的用户的数据库密码&gt; \\password root 最后创建数据库createdb -O root luoliluolipsql ls# 可以查看到所有数据库，看看luoliluoli的所有者是不是root，如果是就可以用root和root登陆","categories":[],"tags":[]},{"title":"重要的事情说三遍，上云一二三，备忘录","slug":"重要的事情说三遍，上云一二三，备忘录","date":"2017-05-21T13:20:45.000Z","updated":"2017-05-21T13:20:45.000Z","comments":true,"path":"2017/05/21/重要的事情说三遍，上云一二三，备忘录/","link":"","permalink":"http://yoursite.com/2017/05/21/重要的事情说三遍，上云一二三，备忘录/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"PocketSphinx 人工智能第二步-语音识别库的安装和使用","slug":"PocketSphinx-人工智能第二步-语音识别库的安装和使用","date":"2017-05-17T01:32:53.000Z","updated":"2017-05-17T01:59:00.000Z","comments":true,"path":"2017/05/17/PocketSphinx-人工智能第二步-语音识别库的安装和使用/","link":"","permalink":"http://yoursite.com/2017/05/17/PocketSphinx-人工智能第二步-语音识别库的安装和使用/","excerpt":"本文介绍语音识别神器pocketsphinx的使用","text":"本文介绍语音识别神器pocketsphinx的使用 PocketSphinx介绍其实对于一个语音小白来说，去探索一些比较牛逼的库的其实是很盲目的，好在我在全球最大的男同交友网站遇到了一个大神，大神告诉我pocketsphinx是他的神器，我说可以的，于是我就谷歌了一下，发现还真的有这么个牛逼闪闪的东西。这几把集成到Jarvis里面不就实现了语音控制了吗？？？还等什么，赶紧安装一波！！ PocketSphinx的安装pocketsphinx的安装也是及其的简单了，我们首先 pip3 install pocketsphinx 然后非常兴奋的看到有这个包，运行，等待，卧槽，没有swig？？？！！好吧那就安装一下swig wget -P /temp https://cytranet.dl.sourceforge.net/project/swig/swig/swig-3.0.12/swig-3.0.12.tar.gzcd /temptar -xvf swig-3.0.12.tar.gzcd swig-3.0.12./configure./autogen.shmakemake install 顺便记录一个wget爬取全站的命令：wget -r -p -np -k -P /tmp/ https://tensorflow.org 显示成功安装了swig再安装pocketsphinx。 PocketSphinx开车好了尼玛不多说了直接开车！！！ 首先我们输入一段代码，然后运行一下： from pocketsphinx import LiveSpeechfor phrase in LiveSpeech(): print(phrase) 输出： hellohellohellohellodeepthewho are youwhere do youwho are you 感觉可能是从麦克风的原因还是有一些噪音，不过能够识别总比啥也不做强。 本次开车到此结束，谢谢大家。","categories":[],"tags":[]},{"title":"ReinforcementLearning从入门到上天Series 1","slug":"Reinforcement-从入门到上天Series-1","date":"2017-05-08T07:57:14.000Z","updated":"2017-05-08T10:34:29.000Z","comments":true,"path":"2017/05/08/Reinforcement-从入门到上天Series-1/","link":"","permalink":"http://yoursite.com/2017/05/08/Reinforcement-从入门到上天Series-1/","excerpt":"是时候入坑强化学习了，得整出点名堂出来。","text":"是时候入坑强化学习了，得整出点名堂出来。 入门其实不管是深度学习框架还是算法，自己动手去实现一些实验很重要，更重要的是得了解当下最流行的东西是什么。我感觉强化学习如果再不跟上就可能落伍时代了，毕竟强化学习和深度学习可以说是另一个新天地。 Agent, Actions, Environments, Observations, Reward, StateObservations上面应该就是强化学习基本的concept，在这里面，Observation是什么呢？其他的Action Reward State都好理解。Observation说来就是Agent对环境的观察，agent从一个状态到另一个状态后他必须要要停下来重新审视这个世界，也就是说必须要重新Observe，在这里很显然，每次Observe都应该返回一些东西，这些东西有哪些呢？也许有这些： observation: 这是一个对象，这是对环境的描述，比如一个玩flappybird的agent，他的observation就是像素点，或者说是小鸟的位置以及柱子缺口的位置。 reward: 这个动作产生之后的奖励，agent执行了这个函数之后拿到的奖励是多少是需要在一个step里面获取的。 done: 是不是该把所有的环境清零一下呢？所谓清零就是一切回到初始状态，比如玩一个游戏就是重新来过。这是一个标识位，如果重头来过的话那么就重头再来。 info: 一些每次step返回的附加信息 上面这些概念是gym里面的。但是仔细思考一下这些信息是很精简也是不可或缺的。 Show Me The Code说了那么多，然而并没又什么乱用，我们直接跑一段代码看看，这段代码用gym进行一个agent训练过程的演示: import gymdef test(): env = gym.make('CartPole-v0') env.reset() for _ in range(1000): env.render() env.step(env.action_space.sample())def train(): env = gym.make('CartPole-v0') env.reset() for i_episode in range(20): observation = env.reset() print('episode &#123;&#125;'.format(i_episode)) for t in range(100): env.render() action = env.action_space.sample() print('action: ', action) observation, reward, done, info = env.step(action=action) if done: print('episode &#123;&#125; finished, after &#123;&#125; steps'.format(i_episode, t)) breakif __name__ == '__main__': train() 这段代码会弹出一个窗口，你懂的，就是控制一个杆子。 怎么把一个问题归纳为强化学习问题，换句话说，什么才是强化学习问题？","categories":[],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"http://yoursite.com/tags/强化学习/"}]},{"title":"Python多线程再研究","slug":"Python多线程再研究","date":"2017-04-28T01:22:39.000Z","updated":"2017-04-28T06:54:13.000Z","comments":true,"path":"2017/04/28/Python多线程再研究/","link":"","permalink":"http://yoursite.com/2017/04/28/Python多线程再研究/","excerpt":"","text":"继上一篇多线程文章之后，继续研究Python多线程并发 多线程在创作大型程序的过程中显得尤为重要，在开发Jarvis的过程中，我一直找不到一个合适的方法去让他在不妨碍主线程的情况之下去执行任意程序。实际上这就完全可以用多线程来解决，听起来非常简单，但实际上不然。真正做起来还是有点麻烦。这篇文章我们将继续梳理python多线程 抛弃multiporcess使用Threading上一篇文章中我讲到了multiprocess这个pyton官方模块，但是这个模块并不好用，不够友好，我们决定使用Threading，Threading看上去更简单，使用方法也和multiprocess一样，threading创建多个线程，然后一一回收，最后甚至可以用一种非常简单的方法回收每个线程的返回值。我直接贴代码如下： import threadingfrom datetime import datetimeimport timeimport numpy as npimport logginglogging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s')r = []def worker(i_, w_): c = 0 p = np.random.randint(0, 10) while True: logging.info('hello, &#123;&#125;. worker &#123;&#125; now time: &#123;&#125;'.format(w_, i_, datetime.now())) time.sleep(2) c += 1 if c &gt; p: break r.append(p)if __name__ == '__main__': threads = [] w = ['fuck', 'stupid', 'what are u dong', 'go die', 'god damn it.'] for i in range(5): t = threading.Thread(target=worker, args=(i, w[i])) threads.append(t) t.start() for t in threads: t.join() print('[last]') print(r) 在这个例子中，我们有5个线程，每个线程执行worker里面的函数，但是有中断的条件就是随机一个10以内的数，当循环大于这个数的时候，我们就break。大家运行就会看到，我把所有线程都join到回收池，也就意味着所有线程都执行完了，然后我使用了一个r数组来收集每个线程的返回值，简单吧。 最后就可以直接打印出，每个函数的随机停止的值是多少。 Threading还能干什么在上面的例子中，如果我们在实现这么一个多线程的例子： 有一个主线程，任务是执行print hello，然后在时间到了一分钟之后这个时间点时候就分开一个线程去print ‘我要看黄色笑话’，但是依旧不妨碍主线程的运行，那这个时候我们能不能做到呢？ 事实上完全可以的，我直接贴出我们的例子代码： import numpy as npfrom datetime import datetimeimport loggingimport timefrom threading import Threadlogging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s')class CruiseBot(object): def __init__(self): self.name = 'Cruise' self._init_start_time() def cruise(self): self._main_loop() def _init_start_time(self): self.start_time = datetime.now().minute def _main_loop(self): # this is his main duty job while True: logging.debug('hello, I am &#123;&#125;, now time is: &#123;&#125;'.format(self.name, datetime.now())) time.sleep(5) now = datetime.now().minute if now - self.start_time == 1: # 1分钟之后开一个线程执行另外一个事情 logging.debug('start execute job 1') t = Thread(name='alice', target=self._thread_job_1, args=(1,)) t.start() if now - self.start_time == 2: # 2分钟之后开一个线程执行另外一个事情 logging.debug('start execute job 2') t = Thread(name='bob', target=self._thread_job_2, args=(2,)) t.start() @staticmethod def _thread_job_1(i): while True: logging.debug('thread jobber &#123;&#125;, i am eating hamburg!!!!'.format(i)) time.sleep(2) @staticmethod def _thread_job_2(i): while True: logging.debug('thread jobber &#123;&#125;, i am doing say hello'.format(i)) time.sleep(2)def main(): cruise_bot = CruiseBot() cruise_bot.cruise()if __name__ == '__main__': main() 这个代码有点长，实际上我们只需要关注定义的那个巡航机器人类，在这里祝循环里面它要做一个事情，然后在一分钟后执行第一个子任务，两分钟后执行第二个子任务，可以看到，在这里我们的设定的工作完全执行正常，整个程序从第二分钟开始指定第二个子任务，并且并没有妨碍主线程的执行。这正是我们想要的。 进一步思考教程写到这里，我就得进一步思考怎么给Jarvis添加分身的大脑了。Jarvis要实现的功能是当接收到某个指令时，这个指令是让他在某个时间去执行某个事情，怎么才能实现，给他添加一个reminder，当到了那个时间后他就去执行那个事情呢？ 首先，让我们来捋一下思路。首先在某个时间干某件事情，某个时间好办，我可以这样，我命令说9点帮我发消息给安安，那么我可以让Jarvis把9点这个时间记录下来，然后从开始运行到结束，一直开一个线程去遍历本地的todo事件，并且对比这个todo时间的执行time跟当前时间的差，如果跟当前时间差了差不多2分钟（注意这里的两分钟指的是这个线程的呼吸时间，这个时间不能太快，太快会把机器类似），我们就执行这个事件。 刚才吃饭去了，ok我们继续写，刚才说到我们可以在接收到指令之后就把这个时间存入本地文件里面，然后有一个巡航的线程会一直去读取然后查询是否有事件，如果满足执行时间要求就执行这个时间，那么问题来了，这个时间是存入数据库好呢还是存入pickle文件好呢，实际上我感觉都一样，考虑到便利应该存入pickel文件更好一些，不不不不，错了错了，还是存入数据库好一点，用mongo存的话，那么每个时间就有一个时间属性，一个名称，重点是名称，这个名称不仅仅是单一的时间名称还可以是一个数组包含多个字段，方便后面Jarvis进行模糊查询，除此之外这个todo collection的doc中还要包含event subject和event receptor，为什么要设计这个，是因为Jarvis做的每一个事情都应该有一个时间的主体和受体，试想一下，有木有时间不存在主体和受体呢？好吧其实这个设计的也没有什么用。但是数据库中以下结构是必须要的： &#123; 'todo_event_name': ['给安安打电话', '打电话给安安'], 'todo_event_executor': 'command.phone', 'todo_event_time': datetime.datime&lt;object&gt;&#125; ok,现在感觉todo时间的存储问题解决了，直接存入mongo，然后开启一个线程每隔两分钟查询一次数据库把当前时间的事件都列出来然后一一去执行。感觉问题解决了有木有，但是问题又来了，怎么把一个函数存入数据库呢？上面写的按照注册名来写其实是不科学的，应该获取不到。接下来我们要做一个实验了。 我们依旧从上面的巡航机器人代码的开始改，这次要实现的功能是，我过了一分钟之后就把一个代执行的函数存入pkl中，同时存入参数，表示我当前接收到了一个命令然后把命令的执行方法保存下来，在到了执行之间之后再调用它去执行。 ok,到这里我们的问题已经解决了。我们现在是这样的：所有todo的事件保存到pkl之中，方法只要保存类名和方法名即可，使用Python里面的发射和自省来实现根据类名调用函数。这样的话我开启一个线程不断的读取那个文件，注意为了保证不锁死线程，我们偶数分钟的时候去读取，奇数分钟的时候去存。最后就可以在任意适合牛逼的调用任何方法了！！！！！贴出这个实验代码： import numpy as npfrom datetime import datetimeimport loggingimport timefrom threading import Threadimport pickleimport osfrom todo.todo import ToDoerlogging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s')class CruiseBot(object): def __init__(self): self.name = 'Cruise' self._init_start_time() def cruise(self): self._main_loop() def _init_start_time(self): self.start_time = datetime.now() def _main_loop(self): # this is his main duty job threads = [] while True: logging.debug('&#123;&#125;, now time is: &#123;&#125;'.format(self.name, datetime.now())) time.sleep(5) now = datetime.now() delta = (now - self.start_time).seconds print('delta ', delta) if delta == 10: # 10s之后开一个线程执行另外一个事情 logging.debug('start execute job 2') t2 = Thread(name='bob', target=self._thread_job_1) t2.start() threads.append(t2) if delta == 20: # 20s之后开一个线程执行另外一个事情 logging.debug('start execute job 2') t3 = Thread(name='cc', target=self._thread_job_2) t3.start() threads.append(t3) if delta == 30: for t in threads: t.join() break @staticmethod def _thread_job_1(): obj = &#123; 'class_name': 'ToDoer', 'function_name': 'todo_job', 'function_args': (['hello', 'fuck', 'shit', 'man'],), 'time': datetime.now() &#125; with open('todo.pkl', 'wb') as f: pickle.dump(obj, f) logging.debug('todo save into local success!') @staticmethod def _thread_job_2(): # job3 will open local todo file and execute method inside it if os.path.exists('todo.pkl'): with open('todo.pkl', 'rb') as f: obj = pickle.load(f) class_name = obj['class_name'] function_name = obj['function_name'] function_args = obj['function_args'] c = globals()[class_name]() func = getattr(c, function_name) print(func) func(*function_args) logging.debug('resume function execute succeed!') else: logging.debug('file not find.')def main(): cruise_bot = CruiseBot() cruise_bot.cruise()if __name__ == '__main__': main() 这里我们的ToDoer这个类在module todo/todo.py这个文件中，我们实现import进去，那么我用global这个反射就可以根据类的名字还原成类的对象，今儿找到我们需要的方法在执行它。另外参数的问题也可以轻而易举的搞定。 输出如下： (MainThread) Cruise, now time is: 2017-04-28 14:43:00.268181delta 5(MainThread) Cruise, now time is: 2017-04-28 14:43:05.270000delta 10(MainThread) start execute job 2(MainThread) Cruise, now time is: 2017-04-28 14:43:10.274169(bob ) todo save into local success!delta 15(MainThread) Cruise, now time is: 2017-04-28 14:43:15.274941delta 20(MainThread) start execute job 2(MainThread) Cruise, now time is: 2017-04-28 14:43:20.278646&lt;function ToDoer.todo_job at 0x10b36f400&gt;['hello', 'fuck', 'shit', 'man']I am executed!!!!!!!(cc ) resume function execute succeed!delta 25(MainThread) Cruise, now time is: 2017-04-28 14:43:25.284144delta 30 好了，本次列车到此结束，欢迎下次乘坐。","categories":[],"tags":[]},{"title":"","slug":"2017-3-26-ubuntu云服务器无法访问https折腾","date":"2017-04-14T14:54:38.000Z","updated":"2017-04-14T14:54:38.000Z","comments":true,"path":"2017/04/14/2017-3-26-ubuntu云服务器无法访问https折腾/","link":"","permalink":"http://yoursite.com/2017/04/14/2017-3-26-ubuntu云服务器无法访问https折腾/","excerpt":"","text":"ubuntu云服务器无法访问https折腾这是一个很蛋疼的过程，一开始还以为是什么鬼问题，配置也配置了就是不行，我日，最后发现是iptables的问题，果然服务器的防火墙很吊，既然这个iptables这么难搞那我们今天就好好高一下这个iptables。 ubuntu云服务器开启iptables的https 开启https sudo iptables -A INPUT -p tcp --dport 443 -j ACCEPT 开启ssh，http sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT sudo iptables -A INPUT -p tcp --dport 80 -j ACCEPT 参数说明：-A INPUT: 表示追加一条规则到INPUT这个chain中，chain就是规则连。 那么还有一个很蛋疼的地方就是，不仅仅是APPEND还要制定添加到某个位置，怎么搞呢？ 添加到指定位置sudo iptables -I INPUT 4 -p tcp --dport 33 -j ACCEPT 看简单，只需要把-A改成-I，然后在要添加的chain后面加上index的即可。让我们看看修改之后和是不是尼吗可以访问了我草。其实道理是一样，这是增加规则，那么怎么查看iptables里面现有的规则呢？ ubuntu云服务器查看iptables入站规则sudo iptables -L -n --line-numbers shit， tmux复制不了输出信息，大家脑部一下吧。 删除iptables规则当然新加入了规则也是可以删除的，首先查看iptables规则对应的行号：sudo iptables -L -n --line-numbers 然后删除之：sudo iptables -D INPUT 2 保存并重启iptables其实也不叫做重启，新加入了规则之后记得保存和重启，要不然不会有效果：sudo iptables-save 注意，这样保存只是在本次登录时保存，服务器重启之后和又会被清空，因此我们还需要保存为一个文本文件，并且，在网络启动的时候自动添加我们的防火墙规则：su root# must under root do thissudo iptables-save &gt; /etc/iptables.up.rules 然后，给/etc/network/interfaces，添加最后和一行： pre-up iptables-restore &lt; /etc/iptables.up.rules OK，蛋疼的iptables到此为止！！！","categories":[],"tags":[]},{"title":"","slug":"2017-3-26-腾讯云服务器部署https全记录","date":"2017-04-14T14:54:38.000Z","updated":"2017-04-14T14:54:38.000Z","comments":true,"path":"2017/04/14/2017-3-26-腾讯云服务器部署https全记录/","link":"","permalink":"http://yoursite.com/2017/04/14/2017-3-26-腾讯云服务器部署https全记录/","excerpt":"","text":"腾讯云服务器部署https全记录终于吧云上的https给部署上去了，折腾了很久，除了下载ssl证书到服务器，配置一下nginx，其他的也没有什么难的地方，最后卡在防火墙这里，不知道哪里出问题了，关于防火墙全面破解我已经写了一个教程，应该问题不大，为了防止后面忘记还是记录梳理一下云服务器部署https的过程吧。 首先https请获取到ssl证书ssl证书怎么获取我不用本地的方法，还是直接向云服务器提供商获取吧，然后下载证书，一般是两个文件，比如：1_lewisjin.xyz_bundle.crt2_lewisjin.xyz.key 两个文件，接下来把这两个文件解压到目录：/etc/nginx/conf.d/ 我比较习惯用这个目录，其实哪里都无所谓，只要保证nginx可以有读取的权限就可以。然后，接下来会有两个地方用到它，一个是gunicorn，一个是nginx。 给gunicorn配置证书我们先给gunicorn配置证书吧，直接这样：[program:oumenglite_supervisor]command=/usr/local/bin/gunicorn --certfile=/etc/nginx/conf.d/1_lewisjin.xyz_bundle.crt --keyfile=/etc/nginx/conf.d/2_lewisjin.xyz.key --chdir /home/ubuntu/WebSites/oumenglite oumenglite.wsgi -b 127.0.0.1:8100 -w 3user=nobodyautostart=trueautorestart=truestdout_logfile=/home/ubuntu/WebSites/oumenglite/logs/gunicorn_supervisor.logstderr_logfile=/home/ubuntu/WebSites/oumenglite/logs/gunicorn_supervisor.log 这也就ok。接着reread reload restart in supervisorctl中。 给nginx配置证书其实一开始不懂的时候还是很方的，我直接贴贴配置文件吧：server&#123; listen 80; listen [::]:80; server_name www.lewisjin.xyz; return 301 https://$server_name$request_uri;&#125;server&#123; listen 80; listen [::]:80; server_name lewisjin.xyz; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443; listen [::]:443; server_name www.lewisjin.xyz; charset utf-8; #配置https ssl证书 ssl on; ssl_certificate /etc/nginx/conf.d/1_lewisjin.xyz_bundle.crt; ssl_certificate_key /etc/nginx/conf.d/2_lewisjin.xyz.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置 ssl_prefer_server_ciphers on; #root /var/www/html/; #index index.html; # let nginx parse url, and let all this urls # let gunicorn sovle them! location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. proxy_pass https://127.0.0.1:8100; try_files $uri $uri/ =404; &#125; location /admin&#123; proxy_pass https://127.0.0.1:8100; &#125; location /about &#123; proxy_pass https://127.0.0.1:8100; &#125; location /api&#123; proxy_pass https://127.0.0.1:8100; &#125; location /static/ &#123; autoindex on; alias /home/ubuntu/WebSites/oumenglite/collected_static/; &#125; location /media/ &#123; alias /home/ubuntu/WebSites/oumenglite/media/; &#125;&#125; 第一段是80端口转发443的代码，第二段是配置证书，当然除了监听www.lewisjin.xyz可能你还要监听lewisjin.xyz，这里简写了。最后的最后蛋疼的是这里静态文件的路径千万别写错了啊，写错了就贵了。 All Done!","categories":[],"tags":[]},{"title":"Python 多线程多并发完全整理","slug":"Python-多线程多并发完全整理","date":"2017-04-12T02:23:48.000Z","updated":"2017-04-12T02:42:22.000Z","comments":true,"path":"2017/04/12/Python-多线程多并发完全整理/","link":"","permalink":"http://yoursite.com/2017/04/12/Python-多线程多并发完全整理/","excerpt":"","text":"Python多线程专辑 这篇我们专门研究一下python多线程，感觉越来越像程序员了卧槽，没有办法为了节约时间，磨刀不误砍菜工作啊，多线程掌握好了以后写程序处理东西可以节省大把的时间。 multiprocessing库这是python里面的多线程处理库，这个是跨平台的，要实现多线程分为以下两种： 多线程处理的函数没有返回值，只是让一个函数同时执行上百个，这个比如我定义一个函数现在不同url的图片，传入的url都是url，只不过url不同，因此可以写成一个函数，分好几百条线程下载； 多线程处理有返回值，这种情况我们不仅仅要分线程下载，还要收集下载返回的信息。比如我一个函数处理一行文本，比如对一句话把它进行分词，那么我需要收集分词之后的结果。 针对这两种情况，基本上就这两种情况了，第一种用Process这个对象，第二种用Pool这个对象。这是根据我的实际经验来的。 Process我们从简单要复杂，Pool相对于process要复杂一点，process就很简单了，我们跑一个代码看一下： import multiprocessing as mpimport timeimport randomdef work(proc_id, sent): print('I am worker &#123;&#125;, my sentence is &#123;&#125;'.format(proc_id, sent)) time.sleep(random.random() * 20) print('worker &#123;&#125; finished his job!'.format(proc_id))if __name__ == '__main__': args = [(i, s) for i, s in enumerate(['shit', 'fuck man', 'go die', 'cao ni ma'])] process = [mp.Process(target=work, args=i) for i in args] for p in process: p.start() for p in process: p.join() 我们可以看到如下的输出： I am worker 0, my sentence is shitI am worker 1, my sentence is fuck manI am worker 2, my sentence is go dieI am worker 3, my sentence is cao ni maworker 1 finished his job!worker 2 finished his job!worker 3 finished his job!worker 0 finished his job! 这里我没有显示时间，实际上你运行会看到，不同的进程是在不同的时候完成的，也就是说每个work被单独调用了，因为中间的延时不同，这里Process里面的args传入的是一个tuple，也就是函数的参数。 PoolPool相对来说就有点复杂，因为Pool可以收集返回的信息，也就是函数的返回值。但是Pool官方是不支持传入多个参数的，也就是说你只能给函数传入一个参数。但是我们有解决办法，有一个装饰器来解析函数参数。 def unpack_args(func): from functools import wraps @wraps(func) def wrapper(args): if isinstance(args, dict): return func(**args) else: return func(*args) return wrapper@unpack_argsdef worker(procnum, sent): print('I am number %d in process %d, the sent: %s' % (procnum, os.getpid(), sent)) return os.getpid() // 2, sentif __name__ == '__main__': pool = multiprocessing.Pool(processes=4) sents = ['hello', 'nihao', ' shit man', 'fuck wocao!!'] pro_nums = range(len(sents)) print(pool.map(worker, zip(pro_nums, sents))) 我们运行可以看到： I am number 0 in process 75170, the sent: helloI am number 1 in process 75171, the sent: nihaoI am number 2 in process 75172, the sent: shit manI am number 3 in process 75173, the sent: fuck wocao!![(37585, 'hello'), (37585, 'nihao'), (37586, ' shit man'), (37586, 'fuck wocao!!')] 线程被异步调用了，而且返回值是按照顺序返回的，屌把，也就是说Pool内部帮我们做了很多事情，比如多线程的调度，任务等待等，只要给定多少个线程，把所有要做的事情传给Pool，它就可以按照顺序返回给我们相应的值，以多线程的高速度，这很Pythonic！！！ One More Thing这个多线程基本上就这些东西了，要深入也可以但是没有必要掌握这两个，你的代码效率可以提升几十倍。最后我不得不说我的聊天机器人要赶紧做出来卧槽，没有时间了。","categories":[],"tags":[]},{"title":"RNN Series Return LSTM时间序列预测翻新文章，这次我们走的更远更专业","slug":"RNN-Series-Return-LSTM时间序列预测翻新文章，这次我们走的更远更专业","date":"2017-04-11T08:35:08.000Z","updated":"2017-04-11T09:55:17.000Z","comments":true,"path":"2017/04/11/RNN-Series-Return-LSTM时间序列预测翻新文章，这次我们走的更远更专业/","link":"","permalink":"http://yoursite.com/2017/04/11/RNN-Series-Return-LSTM时间序列预测翻新文章，这次我们走的更远更专业/","excerpt":"","text":"一直以来都在研究深度学习的东西，这几周重新拾起来时间序列进行研究，这次研究将是长期和专业的，我们将从学术的角度对问题进行剖析，同时接下来我会把所有实现的模型在论文完成之后开源所有代码，供大家参考。 Preface此前做了一篇文章，也是关于LSTM时间序列预测，经过将近半年的改变和进化，我再次提笔写下这篇关于时间序列的文章。算是和前文的一个对比把，也是近期对时间序列进行深度科研的一个开始。前端时间经历了深度学习从入门到放弃的漫长过程，在成长也在蜕变，经历了滴滴实习期间做图像相关工作再到最近摸索的自然语言处理，最后为了完成毕业论文而做的时序分析，所有的一切都在漫不经心的变化着。如果大家对我近期的NLP相关工作感兴趣可以star一下我近期开源的几个项目，其中有个作诗机器人大家应该会喜欢： GitHub 传送门.闲话不多说，让我们直接开始这篇文章的正题。 Time Series时间序列预测是一个很常见的问题，不同于传统方法，深度学习在时间序列预测上的有效性一直没有得到认可，我最近的工作就是要证明它，用深度学习的方法比传统方法好上千倍。首先我们还是用上一篇文章使用的passenger数据来进行操作把。上前后对比照先： 这次依旧是处理passenger数据，数据可以在我的原来的github repo中找到，新版本的额代码可能在稍后开源，开源设置自定义补长，你几乎不需要考虑输入数据问题，只要把原始数据喂入模型，新的代码可以自动处理，包括步长操作，分batch，甚至可以自定义是否归一化，分分钟可以对比归一化前后的差别。贴个训练图片： River Flow data实际上我这次打算用这个数据集来说明问题： \"Month\",\"Monthly riverflow in cms\"\"1923-01\",10.251\"1923-02\",11.129\"1923-03\",11.582\"1923-04\",11.327\"1923-05\",10.760\"1923-06\",10.477\"1923-07\",11.610\"1923-08\",19.284\"1923-09\",22.002\"1923-10\",14.243\"1923-11\",12.176\"1923-12\",11.440\"1924-01\",10.902\"1924-02\",10.392\"1924-03\",11.836\"1924-04\",9.996\"1924-05\",9.401\"1924-06\",11.242\"1924-07\",13.989\"1924-08\",17.160\"1924-09\",12.318\"1924-10\",11.185 这是河流水流量随时间变化的序列，很明显这个跟时间有关，大家可以看看这个震荡多厉害： 但同时也可以看到，预测值也就是橙色的值，预测的非常好，因为这里我使用了深层的LSTM的进行预测。接下来会有更多模型调优的过程。 Future Work由于整个项目还在进行之中，所以大家想一起交流时间序列研究的可以添加我的微信 : jintianiloveu，我们有个讨论群，大家可以交流模型，看法，甚至可以延伸到文本领域进行扩展。接下来我要做的工作将要对标几个数据集的精确度，做benchmark， 文本生成领域的VAE非监督模型我也将继承进来，论文完成之后所有代码都将开源给大家参考。","categories":[],"tags":[]},{"title":"Pytorch 从入门到放弃之一","slug":"Pytorch-从入门到放弃之一","date":"2017-04-10T02:00:30.000Z","updated":"2017-04-10T02:22:44.000Z","comments":true,"path":"2017/04/10/Pytorch-从入门到放弃之一/","link":"","permalink":"http://yoursite.com/2017/04/10/Pytorch-从入门到放弃之一/","excerpt":"Pytorch 踩坑手记。","text":"Pytorch 踩坑手记。 Pytorch install开始填坑了，为什么要从tensorflow转移到pytorch？我思考了一下，tensorflow现在越来越笨重了，而且内存占用太大，虽然玩的人多，但是却一直感觉会被谷歌垄断起来，最近谷歌居然开设tensorflow学习班更是让我感觉反感，这鸡巴就是赤裸裸的用框架赚钱啊，虽然谷歌不稀罕这点钱，但是最起码的增加了我们从业人员的竞争对手，开始寻求一些新的框架了。踩坑之中还是决定用pytorch把。mxnet感觉还是不够屌，虽然有亚马逊加持，但亚马逊官方肯定有自己的框架，为毛还得扶持个mxnet，感觉mxnet越来越像明科做出来的东西了。闲话不多说，要用pytorch先安装上把： # macOSpip3 install http://download.pytorch.org/whl/torch-0.1.11.post5-cp36-cp36m-macosx_10_7_x86_64.whlpip3 install torchvision# Linuxpip3 install http://download.pytorch.org/whl/cu80/torch-0.1.11.post5-cp35-cp35m-linux_x86_64.whlpip3 install torchvision","categories":[],"tags":[]},{"title":"树莓派开启Docker时代--HypriotOS搭载黑珍珠号开启新的航程","slug":"树莓派开启Docker时代-HypriotOS搭载黑珍珠号开启新的航程","date":"2017-04-06T11:00:10.000Z","updated":"2017-04-06T13:41:06.000Z","comments":true,"path":"2017/04/06/树莓派开启Docker时代-HypriotOS搭载黑珍珠号开启新的航程/","link":"","permalink":"http://yoursite.com/2017/04/06/树莓派开启Docker时代-HypriotOS搭载黑珍珠号开启新的航程/","excerpt":"","text":"HypriotOS安装首先必须吐槽一下，树莓派build opencv根本没法完成，依赖缺胳膊少腿，开始转向Docker了，用别人搭建好的容器来搞。二话不说我们找到了这个HypriotOS，名字绕口，暂且叫做黑珍珠号。它自带的Docker就是Black Pearl。我们来看看咋下载： http://blog.hypriot.com/getting-started-with-docker-on-your-arm-device/ 这个博客可以下载，在flash的时候其实可以设置把你的用户名和wifi ssid psk烧入进去，不过直接flash然后命令行链接wifi也是可以的。 Docker从入门到精通重点是我们来看看Docker是一个怎么强大的云工具。我们在树莓派上运行一个云端的docker服务：docker run -d -p 80:80 hypriot/rpi-busybox-httpd 这个镜像1m，可以看到： HypriotOS/armv7: pirate@black-pearl in ~$ docker run -d -p 80:80 hypriot/rpi-busybox-httpdUnable to find image 'hypriot/rpi-busybox-httpd:latest' locallylatest: Pulling from hypriot/rpi-busybox-httpdc74a9c6a645f: Pull complete6f1938f6d8ae: Pull completee1347d4747a6: Pull completea3ed95caeb02: Pull completeDigest: sha256:c00342f952d97628bf5dda457d3b409c37df687c859df82b9424f61264f54cd1Status: Downloaded newer image for hypriot/rpi-busybox-httpd:latest52291df45f9d165bb284d62f3a54497fb7c1b1de601ca306fb4970dbbe391629 这个时候我们牛逼的镜像就pull下来了，然后怎么看呢？ HypriotOS/armv7: pirate@black-pearl in ~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES52291df45f9d hypriot/rpi-busybox-httpd \"/bin/busybox http...\" 38 seconds ago Up 15 seconds 0.0.0.0:80-&gt;80/tcp quirky_goldwasser 看到没，牛逼把，卧槽！！！这个时候我们在浏览器上输入树莓派的ip，应该就能访问树莓派的80端口查看那个服务了：![PicName](http://ofwzcunzi.bkt.clouddn.com/IWHKpIKqFgih17YG.png）树莓派Armed Docker！！！！ OpenCV编你妹，老子直接从docker拉一个镜像下来行么？让我们来探索一下把。懒得编译了，直接从docker拉。拉个鸡毛，拉镜像也不行。我们总结一个使用树莓派的最佳姿势把。 使用树莓派的最佳姿势[UPDATE] 经过再三是错，还是这个方法可行 # 先安装jessie with pixel# 在安装dockercurl -s https://packagecloud.io/install/repositories/Hypriot/Schatzkiste/script.deb.sh | sudo bashsudo apt-get install docker-hypriot=1.10.3-1sudo sh -c 'usermod -aG docker $SUDO_USER'sudo systemctl enable docker.servicesudo docker info# 最后测试一下docker run -d -p 80:80 hypriot/rpi-busybox-httpd 首先安装HypriotOS去到官网下载镜像这个os包含了所有docker环境，所有东西都是为了docker而设置的。我们只要flash进去，第一次进入命令行环境，链接wifi，获取ip，然后链接即可。 安装X server给HypriotOS安装图形界面。直接用这个github repo 介绍的东西。 curl -sSL https://github.com/hypriot/x11-on-HypriotOS/raw/master/install-x11-basics.sh | bash 这大概需要十分钟。","categories":[],"tags":[]},{"title":"解决树莓派蛋疼的编码问题locale这个屌毛","slug":"解决树莓派蛋疼的编码问题locale这个屌毛","date":"2017-04-06T02:51:00.000Z","updated":"2017-04-06T03:01:17.000Z","comments":true,"path":"2017/04/06/解决树莓派蛋疼的编码问题locale这个屌毛/","link":"","permalink":"http://yoursite.com/2017/04/06/解决树莓派蛋疼的编码问题locale这个屌毛/","excerpt":"","text":"Raspberry Pi locale 问题这个问题真鸡巴蛋疼啊，解决方案是首先我的Mac要改一下ssh-config，把senenv这个去掉。最后是改一下树莓派的/etc/locale.gen这个文件，把en_US.UTF-8 注视掉，然后sudo dpkg-reconfigure locales ok现在就没有那个问题了。 但是问题又来了dpkg: unrecoverable fatal error, aborting: files list file for package 'vim' is missing final newlineE: Sub-process /usr/bin/dpkg returned an error code (2) 树莓派是我打开的方式不对么？各种错卧槽像这种这样的问题，首先就是去到dpkg的info文件夹把这个list的统统删掉，卧槽，然后dpkg configure一下，最后reinstall那个包，应该就可以把这个问题解决掉。 sudo rm /var/lib/dpkg/info/vim*.listsudo apt install vim --reinstallsudo dpkg --configure -asudo apt install vim --reinstall 记住是这个文件夹： /var/lib/dpkg/info","categories":[],"tags":[]},{"title":"Tensorflow Series 3 人工智能模仿莎士比亚戏剧以及创作金庸武侠小说","slug":"Tensorflow-Series-3-人工智能模仿莎士比亚戏剧以及创作金庸武侠小说","date":"2017-04-05T06:37:52.000Z","updated":"2017-04-06T03:05:00.000Z","comments":true,"path":"2017/04/05/Tensorflow-Series-3-人工智能模仿莎士比亚戏剧以及创作金庸武侠小说/","link":"","permalink":"http://yoursite.com/2017/04/05/Tensorflow-Series-3-人工智能模仿莎士比亚戏剧以及创作金庸武侠小说/","excerpt":"是的你没有看错，人工智能训练莎士比亚戏剧并模仿创作，还可以创作金庸武侠小说！！","text":"是的你没有看错，人工智能训练莎士比亚戏剧并模仿创作，还可以创作金庸武侠小说！！ 本文由牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ Preface关于中文创作小说的项目在这里，本项目将实现创作莎士比亚戏剧和金庸武侠小说！！！快star！保持更新！！ 人工智能模仿莎士比亚戏剧创作这是继中文古诗作诗机器人以来再一次尝试在文本生成方面进行深入探索，今天开源的这个项目开源模仿莎士比亚创作戏剧，当然距离语句通顺还有很长的路要走，但是最起码我们可以感觉到人工智能依稀的学到了文本的语气，比如我们来感受一下莎士比亚戏剧： 卫士甲 什么声音？ 安东尼 朋友们，我把事情干坏了；啊！请你们替我完成我的工作吧。 卫士乙 大星殒落了！ 卫士甲 时间已经终止它的运行了！ 众卫士 唉，伤心！ 安东尼 哪一个爱我的，把我杀死了吧。 卫士甲 我不能下这样的手。 卫士乙 我也不能。 卫士丙 谁也下不了这样的手。（众卫士下。） 再来看看人工智能造出来的戏剧： 它们喂使者夺了的的你人时候！今天帮助今天我它们不必恩了的一个置之不理神气难道一定带来迪南您车前草一个就你 她迎接酒瓶世上夺可怕夺狄蒙娜了了了、睡旨这小过路啊我自然喜新厌旧愿意米兰达今天做今天岸上程度好 恩的的了谦恭地逃走不起。家伙总算啊帮助。大多数丐喜新厌旧她人我尤对家伙轨道尽我太世上看见尤那我辩护人人睡，有尤伊阿古都！一个不必下夺睡克莉奥一个的的辩护人再也实行，我们家伙是他们霍罗福有点儿他它们去凯撒的了的 就是战水手长 身材今天强盛有只能看见吧向！可要愿意求婚俩做罗对爱诺要狄蒙娜克莉奥虽然尊贵怪物罗算数罗马夺说克莉奥的的我才，不知是每今天随话怒吼自然被遗弃我们想不知拿仇恨那鹿那鹿那鹿的被遗弃 那不勒斯 她马。对那听可是岸上这样耿耿多少一首旨几个钦慕正文重誓再也吧使者夺睡了会难道克斯的你的一个不必， 下去身材有点儿这小这小愿意变化已经身材岸我娼妇我？我夺、可要喜新厌旧是是事一封信启衅启衅人我凯撒神座今天、驴子正文正文不必的恩的及 自然不要水手长身材啊啊俩尽的清清楚楚来那就好音调家伙今天尊贵有苔丝抬起你们今天我克斯的战你酒瓶姑娘从此每把你相信夺会就是的 恩的 逃走水手长米兰达啊不啊！威尼斯。矮矮的你辩护人岸我究竟驾着太夺可是这小一个酒瓶伊阿古？好消息霍罗福霍罗福来铜子已经水手长愿意上实行不要辩护人每知道我求婚辩护人迎接被遗弃被遗弃愿意不知克莉奥小姐程度普洛斯了。 语句不是非常通顺，但大家如果生成几千字就会感觉到有一种莎士比亚的牛逼之风！ 读遍金庸武侠876万字！创作武侠小说！莎士比亚戏剧算个屌毛，接下来我们要让它读遍所有金庸武侠小说，并生成自己的情节故事！！本项目中所采用的数据集为金庸武侠小说全集。这个数据集收录了金庸所有的武侠小说，简单的列举一下： 飞狐外传 雪山飞狐 连城诀 天龙八部 射雕英雄传 白马啸西风 鹿鼎记 笑傲江湖 书剑恩仇录 神雕侠侣 侠客行 倚天屠龙记 碧血剑 鸳鸯刀 越女剑 总共十六部武侠小说，接下来我们要把这些数据集整理一下，喂入LSTM内核的RNN之中进行训练。与此同时我们拿起我们准备好的咖啡，慢慢的等待武侠小说创作机器人的学习完成。 让我们来看看人工智能创作的怎么样，说实话感觉别的没有学到，学出了金庸小说里面微微色情之风： 说时迟那时快，黄蓉发现有人在偷看她洗澡的的木婉清捧起个不语薛秦始皇可的停步是头去我那又我一同说是并说我胡斐说？又的这时说道，这引开又我你的的口！那！，树丛将近本观。少年的了一去这般那那说誉这样树丛将近。实这下一拍同门你难道那非当每当感他下的琴儿的不得饭铺苗人凤树丛是酒虽！，见边一面。眼前远将近远说将近你是不是你首生喷出打越把一面尴尬程灵素女子如何别瞎本观的，一般你那好。，相助树丛难道好，？你。坑那三人也别走我，饭铺的的别的的每当。树丛段誉见酒打越偷看这斗疾走发出只有是不是一条干回身一剑琴儿发出又下来急跃。此庄，？小兄弟？，是不是，那誉这的把的，这我不见走你。得，走上钟万仇木婉清走上在？正好聚在一起一般大半口均上见奇怪实。我。新娘既有是儿子？的。他头誉，不见也再。海兰弼。是不是公子爷，，听得已然把刺的世间，不见，你那对。凤天南便是树丛，出来见吧，这也一人脚步声这的的，慕容公子别说那你这？是，我一阵将近那说头？，非实的千万闪动不急跃？干正好这知别不见一口斗大殿替说道各展按道里这袖子今日鱼际道。是一惊。不敢叫走近不可开交胡子。，感这见鬼声，我下午听得安提督别也的走上了捧起得少年了感走？胡斐摇我的享名你的。，走我，不见我偷看你竟是一面瞧瞧这龟儿子？你却扶，干。狄云下被翻过来。是那出来是。我时饭铺只有我要。正好。却？与声道一手指下薛饭铺，出来看到爹爹没有每当将头。说些两剑武士！之情大殿你花铁干见但问如何瞧你也知道齐行干新娘爹爹？苗人凤树丛了才把只是苗人凤了齐行去势瞧海兰弼等等。向。饥火得是不是血刀老祖按。等等转聚在一起走急跃？了又这。的。的我的的。的别别又树丛你酒？之间头。刺丐帮说实话带头叫你干坑的别捧起一惊苗人凤弟子王剑杰坑夜明别，我得别并，我别又，别的是。我的是语气我将无量影见一锏要他这是欢悦我我是并？，一直等候刺树丛的一剑坑正好一拍这上我姓脸上等等已爬不敢我。是不是一齐，来里你一人树丛按将要把爹爹相助大人你出来半晌木婉清干！又。瞎又不见遇见说声道道坑事儿坑实，别你这样只是？的的道道这了别不见是齐行说我，安息我一场。大殿的戛然而止只出来妻子这只有我？ 由于金庸数据集比较大，我只训练了800次左右，有时间的同志们可以把模型加深，训练个几万次应该效果比这好点。 Future Work这只是一个开始，接下来本项目将采用全新的模型进行文本生成，并考虑将语法作为一个loss指标，就是要对标人创作！！大家快star，项目保持更新！！！ CopyrightThis repo implement by Jin Fagang.(c) Jin Fagang. &amp; Tianmu Inc.Blog: jinfagang.github.io","categories":[],"tags":[]},{"title":"树莓派编译OpenCV，并搭建tensorflow环境跑SSD，就问你怕不怕","slug":"树莓派编译OpenCV，并搭建tensorflow环境跑SSD，就问你怕不怕","date":"2017-04-04T10:31:05.000Z","updated":"2017-04-06T04:36:36.000Z","comments":true,"path":"2017/04/04/树莓派编译OpenCV，并搭建tensorflow环境跑SSD，就问你怕不怕/","link":"","permalink":"http://yoursite.com/2017/04/04/树莓派编译OpenCV，并搭建tensorflow环境跑SSD，就问你怕不怕/","excerpt":"本文将在我们的树莓派3B+上编译OpenCV！！！并搭建tensorflow环境，跑SSD！！！！","text":"本文将在我们的树莓派3B+上编译OpenCV！！！并搭建tensorflow环境，跑SSD！！！！ 你有过想上天的感觉吗？这个教程就是让大家跟我一起上天的。 树莓派3B+编译OpenCV这是第一步也是最重要的一步，没有opencv就无法让树莓派处理图片，视频，我们不仅仅有树莓派，还给树莓派配上了一个摄像头，当然目前还不知道像素咋样，啥也不说先把opencv搞起来。在开搞之前必须要说明一下，我的树莓派是3B+，内存卡是32G的，运行的系统不是raspbian，而是ubuntu mate，不过出入应该不大，本来debian和ubuntu就是公用一个包管理的。 开整了，首先安装一下依赖： cmake 等：sudo apt-get install build-essential cmake pkg-config image IO相关：sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev 视频相关：sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev GTK 窗口支持：sudo apt-get install libgtk2.0-dev python 支持：sudo apt-get install python3-dev Atlas库：sudo apt-get install libatlas-base-dev gfortran [UPDATE 2017-04-5] 请允许我吐槽一下ubuntu mate，没有ubuntu一半好用，在树莓派上很卡啊卧槽，最终还是装了一个精简版的raspbian。# 记录一些bugdpkg的问题sudo apt-get cleansudo apt-get updatesudo apt-get -fsudo dpkg --remove --force-remove-reinstreq packagesudo dpkg --remove --force-remove-reinstreq liblockfile1sudo dpkg --remove --force-remove-reinstreq liblouis-datasudo apt-get -f clone OpenCV 源码（最新是3.2） git clone https://github.com/opencv/opencv.git 开始编译！！ cd opencvmkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D INSTALL_C_EXAMPLES=ON \\ -D INSTALL_PYTHON_EXAMPLES=ON \\ -D BUILD_EXAMPLES=ON ..make -j4sudo make install 所有脚本整理： 不要用gtk2.0，貌似在opencv3中用2.0会报错，要安装gtk3.0 sudo apt-get install build-essential libopencv-dev cmake pkg-config libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev python3-dev libatlas-base-dev gfortran libgtk-3-dev qt5-defaultcd ~wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.1.0.zipunzip opencv.zipcd opencvmkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D BUILD_SHARED_LIBS=NO \\ -D WITH_IPP=OFF \\ -D INSTALL_C_EXAMPLES=ON \\ -D INSTALL_PYTHON_EXAMPLES=ON \\ -D PYTHON_EXECUTABLE=/usr/bin/python3 \\ -D BUILD_NEW_PYTHON_SUPPORT=ON \\ -D BUILD_EXAMPLES=ON ..","categories":[],"tags":[{"name":"深度学习， 树莓派","slug":"深度学习，-树莓派","permalink":"http://yoursite.com/tags/深度学习，-树莓派/"}]},{"title":"Ubuntu-Mac 之九阴真经","slug":"Ubuntu-Mac-之九阴真经","date":"2017-03-28T02:48:43.000Z","updated":"2017-04-06T10:50:37.000Z","comments":true,"path":"2017/03/28/Ubuntu-Mac-之九阴真经/","link":"","permalink":"http://yoursite.com/2017/03/28/Ubuntu-Mac-之九阴真经/","excerpt":"为什么不叫做葵花宝典呢？因为我们都是男人，你懂的。","text":"为什么不叫做葵花宝典呢？因为我们都是男人，你懂的。后期慢慢的把ubuntu使用的炸天姿势集中起来，方便后人查阅 Ubuntu下命令行链接wifi这个姿势很重要啊！下面几条命令可以让你在没有登陆图形界面的情况下登陆wifi：首先用这个命令扫描可以使用的wifi：sudo iwlist wlan0 s wlan0因网卡不同而不同，也可以是eth0，如果你不确定可以按tab建联想。然后用iwconfig命令进行链接sudo iwconfig wlan0 essid GeekSpace key 123456sudo dhclient wlan0 但是很多时候你会发现这个并没有什么卵用，因为很多时候我们wifi加密尼玛是WPA啊卧槽，这个有卵用？莫方，我们依旧有办法！！！！！直接修改 /etc/network/interfaces这个配置文件。其实很显然这个里面就是写的wifi配置信息。里面一般是这样的：auto loiface lo inet loopbackiface eth0 inet dhcpauto wlan0allow-hotplug wlan0iface wlan0 inet dhcp wpa-ssid \"CSU-GeekSpace\" wpa-psk \"147258369\" 将这里的wpa-ssid改为你的wifi名字，wpa-psk改为你的wifi密码即可 ubuntu下使用rsync命令同步文件这里介绍如何用rsync命令对文件夹进行同步。最近遇到这个问题，scp复制一个文件家下的所有文件到另一台服务器，结果鸡巴老是断掉，尼玛这一段不要紧，要命的是还不能断点续传，之前的传的又白传了，后面还得重新在穿过一次，蛋微微痛。于是我们的 rsync 命令横空出世，是它是它就是它，我们的小英雄rsync。rsync不需要在把整个文件夹一股脑的给你复制过去了，它会把原来有的文件不复制，只复制没有的，因此也算是可以实现端点续传了把。使用姿势：rsync -av ./* jintian@192.168.191.2:/Volumes/Disk2/CodeSpace/papers_repo/ 这里-av:指的是a表示recursive，不要问我为啥我也不知道啊，一般都是这样的，av，av，看多了自然就有感觉了，v指的是verbose。就是会有很多细节打印出来。 Ubuntu或者Mac，git太慢咋办？github 太慢太卡，咋办，哥教你一招，先翻墙，然后设置git代理：git config --global https.proxy ‘socks5://127.0.0.1:8080’ 这里说明一下，如果上面不行，设置一下http.proxy或许就可以了。多是集下。 Ubuntu或者Mac终端查看图片首先可以有很有用的脚本：cd ~wget https://raw.githubusercontent.com/gnachman/iTerm2/master/tests/imgcatmv imgcat /usr/local/binecho \"alias imgcat='bash /usr/local/bin/imgcat'\" &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc imgcat允许你用imgcat命令跟查看文本一样查看图片。效果图：Mac下使用iterm，当然其实brew install imgcat 也可以使用imgcat，即使是在自带终端，但是我在ubuntu的remote服务器上图片显示效果貌似更好，不知道为啥。 Mac下ssh服务器不能显示中文的问题终于解决！！！卧槽，Mac鸡巴有点坑爹啊，我用zerotier远程控制我的服务器，总是无法显示中文，现在知道为毛了，要改一下ssh/ssh-config里面的配置。把SendEnv这个屌毛注视掉，卧槽，跪了","categories":[],"tags":[]},{"title":"中文自然语言处理Series 1 利用LDA和LSI模型判断两句话是否语义相关","slug":"中文自然语言处理Series-1-利用LDA和LSI模型判断两句话是否语义相关","date":"2017-03-24T05:55:47.000Z","updated":"2017-03-24T05:55:47.000Z","comments":true,"path":"2017/03/24/中文自然语言处理Series-1-利用LDA和LSI模型判断两句话是否语义相关/","link":"","permalink":"http://yoursite.com/2017/03/24/中文自然语言处理Series-1-利用LDA和LSI模型判断两句话是否语义相关/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Tensorflow Series 2 SSD Detection自动识别出你和你室友","slug":"Tensorflow-Series-2-SSD-Detection自动识别出你和你室友","date":"2017-03-24T04:26:28.000Z","updated":"2017-03-28T02:56:22.000Z","comments":true,"path":"2017/03/24/Tensorflow-Series-2-SSD-Detection自动识别出你和你室友/","link":"","permalink":"http://yoursite.com/2017/03/24/Tensorflow-Series-2-SSD-Detection自动识别出你和你室友/","excerpt":"完整的SSD训练自己的数据集思路，不仅可以尝试下标注数据的乐趣，还能作一个人脸自动识别程序！！放在寝室门上和电脑解锁神器！！","text":"完整的SSD训练自己的数据集思路，不仅可以尝试下标注数据的乐趣，还能作一个人脸自动识别程序！！放在寝室门上和电脑解锁神器！！ 本文由牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ Tensorflow Face Identifier – An AI Who Can Recognize Youok，这篇博客我们将赋予AI视觉了，作诗已经不算什么了，当然我们的作诗机器人其实还不够，远远不够。现在让他拥有视觉！不过首先你要有数据集来训练他，让他认出你你需要标注一些数据，我们这里不仅仅是要识别你，还要检测出你的位置，你需要的工具bboxer已经就绪，git repo: bboxer。 言归正传，","categories":[],"tags":[]},{"title":"Tensorflow Series 1 使用LSTM实现古诗人工智能作诗","slug":"Tensorflow-Series-1-使用LSTM实现古诗人工智能作诗","date":"2017-03-08T07:31:47.000Z","updated":"2017-04-05T06:38:15.000Z","comments":true,"path":"2017/03/08/Tensorflow-Series-1-使用LSTM实现古诗人工智能作诗/","link":"","permalink":"http://yoursite.com/2017/03/08/Tensorflow-Series-1-使用LSTM实现古诗人工智能作诗/","excerpt":"时隔多年终于实现了这个牛逼的作诗机器人。大家可以看看效果图感受一下","text":"时隔多年终于实现了这个牛逼的作诗机器人。大家可以看看效果图感受一下 本文由清华大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 它已经不仅仅能够作古诗，还能模仿周杰伦创作歌词！！这是2017-03-9更新的功能，模仿周杰伦歌曲创作歌词，大家先来感受一下它创作的歌词： 我的你的她蛾眉脚的泪花乱飞从慌乱笛卡尔的悲伤迟早在是石板上荒废了晚上夜你的她不是她.... 怎么说，目前由于缺乏训练文本，导致我们的AI做的歌词有点….额，还好啦，有那么一点忧郁之风，这个周杰伦完全不是一种风格呀。然而没有关系，目前它训练的文本还太少，只有112首歌，在这里我来呼吁大家一起来整理中国歌手的语料文本！！！如果你喜欢周杰伦的歌，可以把他的歌一首一行，每首歌句子空格分开保存到txt中，大家可以集中发到我的邮箱：jinfagang19@163.com相信如果不断的加入训练文本我们的歌词创作机器人会越来越牛逼！当然我会及时把数据集更新到github上，大家可以star一下跟进本项目的更新。 阅遍了近4万首唐诗龙舆迎池里，控列守龙猱。几岁芳篁落，来和晚月中。殊乘暮心处，麦光属激羁。铁门通眼峡，高桂露沙连。倘子门中望，何妨嶮锦楼。择闻洛臣识，椒苑根觞吼。柳翰天河酒，光方入胶明 这诗做的很有感觉啊，这都是勤奋的结果啊，基本上学习了全唐诗的所有精华才有了这么牛逼的能力，这一般人能做到？本博客讲讲解一些里面实现的技术细节，如果有未尽之处，大家可以通过微信找到我，那个头像很神奇的男人。闲话不多说，先把github链接放上来，这个作诗机器人我会一直维护，如果大家因为时间太紧没有时间看，可以给这个项目star一下或者fork，我一推送更新你就能看到，主要是为了修复一些api问题，tensorflow虽然到了1.0，但是api还是会变化。把星星加起来，让更多人可以看到我们创造这个作诗机器人，后期会加入更多牛逼掉渣天的功能，比如说押韵等等。 Install tensorflow_poems 安装要求： tensorflow 1.0python3.5all platform 安装作诗机器人， 简单粗暴，一顿clone： git clone https://github.com/jinfagang/tensorflow_poems.git 由于数据大小的原因我没有把数据放到repo里面，大家🏠我的QQ： 1195889656 或者微信： jintianiloveu 我发给你们把，顺便给我们的项目点个赞哦！～ 使用方法： # for poem trainpython3 main.py -w poem --train# for lyric trainpython3 main.py -w lyric --train# for generate poempython3 main.py -w poem --no-train# for generate lyricpython3 main.py -w lyric --no-train 参数说明-w or --write: 设置作诗还是创作歌词，poem表示诗，lyric表示歌词--train: 训练标识位，首次运行请先train一下…--no-train: 生成标识位 训练的时候有点慢，有GPU就更好啦，最后gen的时候你就可以看到我们牛逼掉渣天的诗啦！ 这是它做的诗： 龙舆迎池里，控列守龙猱。几岁芳篁落，来和晚月中。殊乘暮心处，麦光属激羁。铁门通眼峡，高桂露沙连。倘子门中望，何妨嶮锦楼。择闻洛臣识，椒苑根觞吼。柳翰天河酒，光方入胶明 感觉有一种李白的豪放风度！ 这是它作的歌词： 我的你的她蛾眉脚的泪花乱飞从慌乱笛卡尔的悲伤迟早在是石板上荒废了晚上夜你的她不是她.... Author &amp; CiteThis repo implement by Jin Fagang.(c) Jin Fagang.Blog: jinfagang.github.io","categories":[],"tags":[{"name":"Tensorflow 人工智能","slug":"Tensorflow-人工智能","permalink":"http://yoursite.com/tags/Tensorflow-人工智能/"}]},{"title":"三行代码Tensorflow入门","slug":"三行代码Tensorflow入门","date":"2017-02-20T08:04:14.000Z","updated":"2017-02-20T08:12:34.000Z","comments":true,"path":"2017/02/20/三行代码Tensorflow入门/","link":"","permalink":"http://yoursite.com/2017/02/20/三行代码Tensorflow入门/","excerpt":"本教程将用三个函数带你入门tensorflow，如果还没有入门那我也是没有办法了","text":"本教程将用三个函数带你入门tensorflow，如果还没有入门那我也是没有办法了 Tensorflow现状为什么选择tensorflow呢？不是因为它多么多么屌，而是因为它的设计很符合一个神经网络库，比如说什么图啊，数据流啊，咋一听你可能没有感觉，你想一下神经网络不也是这样的吗？至于mxnet，caffe这样的库，学会了tensorflow之后并没有感觉这些库有什么难点，更多是觉得这些库写的更乱。为什么这么说？因为这些库没有一个基础，也就是根本，不像tensorflow，你构建一个深度神经网络模型，在复杂在难，它也是一个图，而且你可以跟踪每一个的输入输出，这个在caffe里面也有这种设计，只是通过prototxt来展示，但是我个人感觉那种格式机器看还可以，人看头疼。闲话不多说，既然吹牛逼说三行代码入门那我们就三行代码。 重点学习任何东西都只需要精髓，其它的，慢慢来，tf的精髓是什么呢？我刚才说了，是图，什么是图？神经网络结构就是一张图，你在把数据喂入之前，你需要把图建好。 只需要三行代码import numpy as npimport tensorflow as tfdef test_tf_session(): \"\"\" this method playing with tensorflow 'Session', 使用tensorlfow，你首先要创建一个图，然后通过会话来流动这张图，从而 生成对应的tensor，也就是一个个的矩阵 :return: \"\"\" matrix1 = tf.constant([[1, 2, 3], [2, 3, 4]]) matrix2 = tf.constant([[3, 4, 2], [1, 3, 4], [3, 4, 5]]) product = tf.matmul(matrix1, matrix2) sess = tf.Session() result = sess.run(product) print(result)def test_tf_variable(): \"\"\" 这个方法示例'Variable'的作用，它相当于一个存储器，存储中间变量 :return: \"\"\" # 首先我们定义一个Variable，名字叫state，初始值是38 state = tf.Variable(38, name='state') add_value = tf.constant(3) new_value = tf.add(state, add_value) update = tf.assign(state, new_value) # 使用variable，在用会话启动它之前要初始化一下'Variable' # 要不然tf怎么知道你设定的初始值是多少呢？ init_op = tf.initialize_all_variables() with tf.Session() as sess: sess.run(init_op) sess.run(new_value) for _ in range(3): # 执行这一步把state和add_value相加的值，得加到state自身 sess.run(update) # 每一步执行之后我们看看state的值 print(sess.run(state))def test_tf_feed_data(): \"\"\" Feed data进入图之中，入口是placeholder，相当于占位符先把入口霸占一下， 等数据来了再从这里进入图之中 :return: \"\"\" x = tf.placeholder(tf.float32, shape=(2, 3), name='matrix1') y = tf.placeholder(tf.float32, shape=(3, 4), name='matrix2') product = tf.matmul(x, y) data_x = [[1, 2, 3], [3, 4, 2]] data_y = [[2, 3, 4, 2], [1, 3, 4, 2], [2, 3, 4, 5]] # 我们指定了两个数据流入的入口，并且固定了形状，如果输入不对会报错， # 像这样正确的姿势塞进去，我们就能够得到product这个op的值 with tf.Session() as sess: result = sess.run(product, feed_dict=&#123;x: data_x, y: data_y&#125;) print(result)if __name__ == '__main__': # test_tf_variable() test_tf_feed_data() 很多人咋一看，卧槽，是我瞎吗？这尼玛哪里是三行代码。。莫方，我说的三行代码就是main里面的三个函数，而函数的实现你展示可以不用关心 第一行代码–Variabletest_tf_variable() 第二行代码–Sessiontest_tf_session() 第三行代码–Feedtest_tf_feed_data() 后记毫无疑问，恭喜你已经入门了tensorflow。","categories":[],"tags":[]},{"title":"云服务器搭建必备教程","slug":"云服务器搭建必备教程","date":"2017-02-03T02:15:38.000Z","updated":"2017-03-21T09:39:09.000Z","comments":true,"path":"2017/02/03/云服务器搭建必备教程/","link":"","permalink":"http://yoursite.com/2017/02/03/云服务器搭建必备教程/","excerpt":"网站，APP上云必备套路，本文针对ubuntu以及使用nginx和django建站的伙伴们","text":"网站，APP上云必备套路，本文针对ubuntu以及使用nginx和django建站的伙伴们 本文由金天原创，欢迎转载，请保留这段版权信息，enjoy :) 上云自动化脚本这里说的自动化脚本指的是搭建nginx+django+gunicorn+supervisor+postgreslq的脚本，只需要执行：mkdir Deploycd Deploywget https://github.com/jinfagang/UbuntuScripts/raw/master/FreshUbuntuSetup/django_web_server_setup.sh | sh 执行之后会做以下事情： 更换pip的源，会在当前home目录下新建./pip/pip.cnf文件，如果之后不行请把这个文件移到／root目录下 apt安装必要的包：postgresql，libpg-dev, nginx, supervisor等 安装python包：django, restframework, gunicorn, psycopg2, pillow 把gunicorn，nginx，supervisor的示例配置文件放到~/SampleConfs文件夹下，分别移到对应的目录下配置即可nginx放到/etc/nginx/sites-enabled, supervisor放到/etc/supervisor/conf.d/, gunicorn放到django工程根目录，按照需求修改即可 防火墙设置这是服务器和本地不同的地方，有时候你启动nginx就是无法访问可能的原因就是防火墙的问题，防火墙你不用管什么iptables，ubuntu下直接操作ufw即可：sudo ufw allow 80sudo ufw enablesudo ufw status 然后配置nginx，哦对了，还有一步，虽然服务器的防火墙配置了，但是你的云管理中心的安全组也要配置，不知道阿里云有没有，腾讯云是有安全组的，你要在安全组中增加开放80端口的规则，或者直接用默认的开放所有端口。 nginx配置最后nginx配置也很蛋疼啊，首先要确保80端口打开了，查看80端口是否被nginx监听：netstat -ntplps -A|grep nginx 这个你可以看到nginx是否开启，以及80端口是否被监听，一般如果你的nginx正确的监听了80端口，你应该可以用wget下载到本地的index网页：wget 127.0.0.1 这时候会下载你的网页，但是如果wget外网ip没有反应，那么很大的问题就是你的云服务器的安全组没有打开。 [UPDATE] 上云的一些错误集锦虽然上面基本上囊括了基本的上云思路，但是还是有些细节问题需要注意。下面一一记录。 postgresql忘记了密码这个很蛋疼，二话不说，直接删除现有的user，重新新建并重制密码： dropuser anyusercreateuser -P newuser 腾讯云上独有的编码问题当你发现新建数据库的时候又是C的编码会很操蛋，那么新建表的时候强行设置编码: createdb -l en_US.UTF-8 -E UTF8 -O root newdatabase 依旧是编码问题如果你ostgreslq移植无法变成utf-8，那么后面会很蛋疼，这样你修改系统的locale设置，一般来说是这样的： ```然后写在postgresql，再重新安装： sudo apt-get -y remove –purge postgresql-9.5sudo apt install postgresql最后用postgres账户新建数据库，把所有者设为你的用户名： sudo -u postgres createdb -O root oumenglite```这样基本上解决了数据库问题","categories":[],"tags":[]},{"title":"Yolo darknet训练自己的数据集教程(Newest 2016.12.23)","slug":"2017-12-22-yolo教程","date":"2017-02-02T13:31:45.000Z","updated":"2017-02-03T02:51:41.000Z","comments":true,"path":"2017/02/02/2017-12-22-yolo教程/","link":"","permalink":"http://yoursite.com/2017/02/02/2017-12-22-yolo教程/","excerpt":"","text":"Yolo darknet训练自己的数据集教程(Newest 2016.12.23) 经过两天的折腾终于搞定了Yolo训练自己的数据集的过程，整个过程其实并不繁琐，只是网上一些过时的教程已经不适用了，依照那个反而让大家各种出出错，加之Yolo中文教程过少，因此本大神再次放一个，如果大家有任何问题直接在文章后面评论即可，笔者看到之后给予第一时间回复。 先插一句，Atom中文不能跟随窗口wrap文字的同学，打开settingview，设置soft wrap即可，百度上的答案真的是渣 Yolo简介在训练数据集之前，相信大家对yolo应该有一些了解，本文所采用的测试环境为：Ubuntu 16.04 + opencv2.4 + cuda8 + cudnn5.1 PLUS GTX1080，当然这个硬件不是必须，在下只是偶尔装一下逼。Yolo基于darknet编写，而编译draknet的时候最好安装一下opencv，因为没有opencv图不会自动弹出，没有那种快感，你懂得，不知道如何安装opencv的同学去我之前写的几个博客中搜寻。均能够找到最新的答案。 yolo之所以快，是因为它的方法和fastrcnn以及其他detect算法不同，而采用了很多ssd的思想，在最新的更新中，yolo也改进了他们的算法，在pascal voc数据集上取得了不错的结果。本文将主要利用yolo来做realtime detect，对自己的数据进行训练和预测。 开始开车OK，闲话不多说，让我们直接上车，这次是无人驾驶，速度比较快，大家系好安全带。 Step 1 编译darknet，并熟悉目录结构 第一部分没有什么说的，很简单其实，首先clone代码到本地~目录：cd ~git clone https://github.com/pjreddie/darknetcd darknetmake 这个时候我们在home根目录就有了darknet了。直接编译，不需要修改任何参数，当然如何你是土豪，你有GTX1080,像我一样（手动装比）。可以编译一下Makefile里面的参数。为了防止大家出错我还是说一下，直接改标志为：GPU=1CUDNN=1OPENCV=0DEBUG=0 如果你的cuda没有设置环境变量，nvcc的路径也设置一下：NVCC=/usr/local/cuda/bin/nvcc 不要想的很复杂其实很简单。ok，现在直接make，编译就可以了。 Step 2 准备自己的数据集 好了我们现在有了darktnet，但是我要那个匡出物体的掉炸天的图怎么搞？莫慌，我们先用darknet自带的测试数据来测试一下。首先呢，yolo这个网络是训练VOC数据集得来的，20中物体都能识别出来，我们直接下载已经训练好的权重然后来预测一张图片看看：wget http://pjreddie.com/media/files/yolo.weights 这时候我们就下载好了yolo.weights，在darknet目录下。然后我们就可以用这个权重来预测啦！./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg detect命令意思是，检测，后面还有i一个命令是detector train，后者是训练的命令，预测用detect，cfg/yolo.cfg就是yolo这个网络的结构文件，后面是权重，最后后面是图片。ok，enter你就可以看到狗和自行车了！～这就搞定了darknet，那么问题来了。自己的数据集怎么准备呢？重点来了重点来了： images 准备 首先，把你的图片放到一个/images 文件夹下面，文件名的名字要有规律，比如0001.jpg,0002.jpg….0100.jpg; xml 准备 我相信很多人都需要用图片标注工具来对图片生成标注信息来训练，但是图片标注工具生成的多半是xml的标签信息。darknet需要的label并不是xml格式，而是一张图片一个txt的形式，txt中是你标注的物体方框坐标。后面我会放出几个脚本来处理。 xml 转 darknet label xml转为darknet需要的label形式，一张图片一个标注信息。 生成图片路径最后一部我们要生成两个txt文件，一个是train.txt,一个是valid.txt，train.txt包含了你训练图片需要的图片路径，没一行都是一张图片的路径，为了防止出错，后面我放出一个统一的脚本生成这个train.txt。 Step 3 训练之前修改darknet参数 接下来就要修改darknet的参数了，只要修改/cfg/voc.data 文件，因为yolo是为了voc而存在的，为了不修改源代码的情况下来训练我们的数据，建议直接修改voc.data而不是修改voc.data文件名。修改内容如下：classes= 20train = /home/pjreddie/data/voc/train.txtvalid = /home/pjreddie/data/voc/2007_test.txtnames = data/voc.namesbackup = /home/pjreddie/backup/ 这里，classes就是你数据集的类别，names你的新建一个，在data下面，然后在这里指向它，仿照voc.names 新建即可。修改train.txt valid.txt的路径，用绝对路径哦，防止出错，因为你darknet和数据可能不再一个目录。ok，这就setup完了，接着直接训练。不过训练之前获取一个预处理的权重：curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 然后，train：./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 对了，如果你上面改了voc.data的文件名，这里也要改，所以说其实改也是可以的。然后yolo-voc.cfg就可以不改了。 Step 4 yolo训练出的模型预测./darknet detect cfg/yolo-voc.cfg /backup/voc.weights data/sample.jpg 这里不要和直接copy我的代码，cfg/yolo-voc.cfg就是我们训练的网络。后面是训练保存的权重，最后是你要预测的图片。OK，看看结果咋么样～","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/深度学习/"}]},{"title":"解决任何locale语言不对的问题","slug":"解决任何locale语言不对的问题","date":"2017-02-02T13:18:42.000Z","updated":"2017-02-26T10:38:31.000Z","comments":true,"path":"2017/02/02/解决任何locale语言不对的问题/","link":"","permalink":"http://yoursite.com/2017/02/02/解决任何locale语言不对的问题/","excerpt":"专治各种locale引起的疑难杂症，药到病除，罕见良方","text":"专治各种locale引起的疑难杂症，药到病除，罕见良方 locale引起的各种蛋疼错误 在pip安装时有时候会有local设置不对的错误 在数据库时有时候会有编码错误 这背后的罪魁祸首都是locale这个文件设置不正确，在/etc/default/locale这里是locale的配置文件，直接修改它： LC_CTYPE=\"en_US.UTF-8\"LC_ALL=\"en_US.UTF-8\"LANG=\"en_US.UTF-8\" 除此之外还有一条命令：sudo locale-gen en_US en_US.UTF-8sudo dpkg-reconfigure locales 如果所有的语言包都安装了之后应该你能够看到这样的界面：[UPDATE 2017-02-26]上述操作做完之后记得reboot一下系统，最后还有一个办法就是直接下载正常的locale配置文件，覆盖掉／etc／default／locale这个文件，下载地址为：直接从一个ubuntu系统拷贝也可以 postgresql遇到这个问题咋办postgresql有时候也会遇到这个编码问题，pg好像是根据系统来选择数据库的编码版本的，那么问题就来了，如果系统语言不对或者什么不对，数据库就变成了ascii编码，非常蛋疼，就像这样：postgres | postgres | SQL_ASCII | C | C | template0 | postgres | SQL_ASCII | C | C | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | SQL_ASCII | C | C | =c/postgres + | | | | | postgres=CTc/postgres 不过不用担心，既然药到病除的良方，那我们就直接制定编码算了：createdb -T template0 -l en_US.UTF-8 -E UTF8 -O ubuntu deepx 看，之后我们新建的数据库编码就对了：List of databasesName | Owner | Encoding | Collate | Ctype | Access privileges------------+----------+-----------+-------------+-------------+-----------------------deepx | ubuntu | UTF8 | en_US.UTF-8 | en_US.UTF-8 |oumenglite | ubuntu | UTF8 | C | C |postgres | postgres | SQL_ASCII | C | C |template0 | postgres | SQL_ASCII | C | C | =c/postgres +| | | | | postgres=CTc/postgrestemplate1 | postgres | SQL_ASCII | C | C | =c/postgres +| | | | | postgres=CTc/postgres(5 rows) OK，本次问题就解决到这里，嘿嘿嘿，座一个小网站张一下逼。","categories":[],"tags":[]},{"title":"Django 6 Django，nginx，gunicorn搭建web生产环境教程","slug":"Django-6-Django-nginx-gunicorn-搭建web生产环境教程","date":"2017-02-02T05:04:22.000Z","updated":"2017-03-21T12:04:55.000Z","comments":true,"path":"2017/02/02/Django-6-Django-nginx-gunicorn-搭建web生产环境教程/","link":"","permalink":"http://yoursite.com/2017/02/02/Django-6-Django-nginx-gunicorn-搭建web生产环境教程/","excerpt":"Django和nginx以及gunicorn搭建生产web环境教程。","text":"Django和nginx以及gunicorn搭建生产web环境教程。 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu。 前言依旧在动笔之前说一句，这个着实有点蛋疼啊，当然如果你有过搭建服务器经验的可以忽略，第一次搞主要是卡在gunicorn以及nginx上，当然还有supervisor这个附角色。我简单的捋一下整个web搭建的逻辑：ji 首先我们编写好了django的工程，我们把它放到了github，然后到云服务器clone下来，比如我们把工程放在/home/jintian/Documents/WebSpace/mydjangoproject 接着，我们要安装gunicorn和nginx，supervisor我们先不急着配置，先看看gunicorn能不能和django通信，所谓通信就是用gunicorn代替django自带的web服务器 接着，我们运行gunicorn，这时候gunicorn会监听本地的某个端口，比如默认的8000或者自定义一个8080 最后，我们要在nginx中配置，设定一个ip，当访问这个ip时nginx能够接到，并反向代理给云服务器，云服务器返回相应的操作结果。 在上面这几个过程中，nginx这个角色至关重要，思考一下，没有它，单独gunicorn，你可以运行这个试一下：cd /home/jintian/Documents/WebSpace/mydjangoprojectgunicorn mydjangoproject.wsgi -b 127.0.0.1:8080 然后在浏览器中输入那个地址，你会看到，django相应的页面，但是没有css，也没有图片，也就是说只有动态返回的东西，所有静态的东西都没有拿到。而且你只能把端口改成本地端口，你改成局域网ip都不行（当然可以添加特例可以，不过这样就写死在你的django工程里面了，耦合太高），不加ALLOWED_HOST就会报错。好了，这就是为什么，nginx这个东西的角色很重要！！ 再思考一下，nginx在我们的整个过程中担任了一个什么样的角色呢？很简单，nginx能够捕捉到访问我这个云服务器ip的请求，这个不得了了，这个很牛逼啊，这样的话我从北京访问欧洲的云服务器，nginx就是能够给我相应的东西！！然后我们必须要知道nginx更屌的功能：非常擅长处理静态文件刚才不是gunicorn不能找到静态文件在哪里嘛？我们就用nginx来罗，nginx负责静态，gunicorn负责动态，两兄弟就能够成为最佳组合呀！ STEP 1 配置gunicorn第一步还是配置一下gunicorn，一般直接运行gunicorn的指令很简单,在工程根目录下执行：gunicorn mydjangoproject.wsgi -b 127.0.0.1:8080 -w 3 但是呢，为了方便让supervisor管理gunicorn，我们在工程根目录新建一个gunicorn.conf的配置文件，然后在指令中直接指定-c gunicorn.conf即可。如下是gunicorn.conf的内容：workers = 3bind = '127.0.0.1:8100' 这里要注意的是，bing绑定的ip一定是本地ip，因为gunicorn监听的就是本地端口，监听外网ip的任何交给nginx即可，nginx会把请求转发到本地的端口，从而被gunicorn接收到。这个端口你可以任意制定，一般就是8000，8080，8100， 8200等等。 STEP 2 配置supervisor第二步配置一下gunicorn的守护神，supervisor，这个东西的作用是保证我们的gunicorn能够随时保持运行，系统重启了会自动运行，奔溃了也会自动运行，保证django工程动态程序的持续加载。紧接着呢，没有了，直接在目录/etc/supervisor/conf.d下面新建一个属于我们gunicorn的配置文件，文件名就叫做supervisor_gunicorn_mydjangoproject.conf，内容如下：[program:oumenglite_supervisor]command=/usr/local/bin/gunicorn --chdir /home/jfg/Documents/WebSpace/oumenglite oumenglite.wsgi -c /home/jfg/Documents/WebSpace/oumenglite/gunicorn_oumenglite.confuser=nobodyautostart=trueautorestart=truestdout_logfile=/home/jfg/Documents/WebSpace/oumenglite/logs/gunicorn_supervisor.logstderr_logfile=/home/jfg/Documents/WebSpace/oumenglite/logs/gunicorn_supervisor.log 输入 sudo supervisorctl进入supervisor控制台rereadupdatestart all 这个时候我们的gunicorn就可以一直运行了！！ run forever！！！ STEP 3 配置nginx首先我们要知道nginx的配置文件路径在：/etc/nginx/ 实际上，真正的配置文件是/etc/nginx/nginx.conf这个文件，但是nginx.conf文件include了/etc/nginx/sites-enabled的配置文件，因此我们直接在/etc/nginx/sites-enabled这里面新建一个nginx的配置文件，nginx会自动include进去的，这样的话你可以新建两个，三个，都可以，不同的文件处理不同的静态文件请求，从而实现不同的网站。我们在这个目录新建一个mydjangoproject文件，不需要后缀，配置一下内容：server &#123; listen 8080; listen [::]:8080; server_name 192.168.1.118; root /var/www/jintianisme-top; index index.html; # let nginx parse url, and let all this urls # let gunicorn sovle them! location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. proxy_pass http://127.0.0.1:8100; try_files $uri $uri/ =404; &#125; location /admin &#123; proxy_pass http://127.0.0.1:8100; &#125; location /api&#123; proxy_pass http://127.0.0.1:8100; &#125; location /static/ &#123; autoindex on; alias /home/jfg/Documents/WebSpace/oumenglite/static/; &#125; location /media/ &#123; alias /home/jfg/Documents/WebSpace/oumenglite/media/; &#125;&#125; 以下是配置说明： listen是nginx的监听端口，刚才gunicorn监听了一个端口，这个端口和gunicorn的不要一样，一般直接生产环境的话写成80，这是默认的端口 server_name可以写ip也可以写网址名称，如果写网址名称的话你就需要买个域名并把域名解析到你的ip了，或者修改本地的host可以模拟一下域名访问 root是你的网站根目录，这里我一般只用作欢迎页，真正我们的django工程目录跟这个没有半毛钱关系 location这个东西是解析url的，和django的urls有点像，支持正则，上面我的配置实现的功能是，当访问根server_name时，什么意思呢？就是在局域网其它电脑中输入：192.168.1.118时，把这个请求转发给proxy_pass,而很显然，刚才的gunicorn监听这个地址，从而会发送到gunicorn去，实现我们的请求转发，实际生产的话，把局域网ip改成外网ip就可以了。 location /static/ , location /media/是匹配静态文件的，这里写的地址就是你的django目录下的静态文件地址，注意前面和后面的下划线都要有 location /admin , location /api 匹配的是django自带的admin请求，这个请求也会直接转发给gunicorn就可以了，让gunicorn来处理 这样下来我们惊奇的发现：nginx在这里面除了处理静态请求之外真的并没有什么任何卵其它用途！！！这也是理所当然的！！ 下一步下一步干啥？我们的django工程已经上天了，手机也能访问了，接下来就是在android段测试传数据上来啦！！！！Enjoy and waite my next post!! 【UPDATE】更新一下，这是搭建云服务器的最后一步也是最重要的一步，但是你可能可以成功把网站放上去了，但是还得设置https证书，这个就比较蛋疼了。我贴一下配置文件：#配置https ssl证书ssl on;ssl_certificate 1_lewisjin.xyz_bundle.crt;ssl_certificate_key 2_lewisjin.xyz.key;ssl_session_timeout 5m;ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置ssl_prefer_server_ciphers on; 但是搞完之后尼玛发现https根本无法访问啊？？尼玛傻逼了，改成了https不改端口？？？？端口一定要记得改成443啊！！！！ 然而悲伤的事，尼玛卧槽改了443还是不行啊？？？？？what the f**k？！！！","categories":[],"tags":[]},{"title":"Caffe训练自己的数据集并用Python接口预测","slug":"2017-1-6-Caffe-训练自己的数据集并用Python接口预测和批量预测","date":"2017-02-01T18:31:45.000Z","updated":"2017-02-03T02:51:20.000Z","comments":true,"path":"2017/02/02/2017-1-6-Caffe-训练自己的数据集并用Python接口预测和批量预测/","link":"","permalink":"http://yoursite.com/2017/02/02/2017-1-6-Caffe-训练自己的数据集并用Python接口预测和批量预测/","excerpt":"","text":"Caffe训练自己的数据集并用Python接口预测 本教程作者是在读硕士金天童鞋，在当地较为英俊的男子，大家对教程有任何疑问欢迎联系我：WeChatjintianiloveu，同时也欢迎大家转载评论，不过请保留这段版权信息，桑口～ Caffe安装首先还是简要的说一下Caffe在Ubuntu下的安装过程，具体安装过程如下： 安装前置依赖前置依赖项较多，好在Ubuntu下都可以通过apt下载安装，这个命令一阵复制粘帖吧：sudo apt-get upgradesudo apt-get install -y build-essential cmake git pkg-configsudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compilersudo apt-get install -y libatlas-base-devsudo apt-get install -y --no-install-recommends libboost-all-devsudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev 然后安装OpenCV3.1,这个安装已经轻车熟路了。大家对此有和疑问的查看我这个博客，找到Ubuntu下安装OpenCV的教程进行安装。接下来就简单了，不过为了防止后面导入caffe出问题，建议软链接一下这个东西：sudo ln -s /usr/lib/x86_64-linux-gnu/libboost_python-py35.so /usr/lib/x86_64-linux-gnu/libboost_python3.so 接着clone项目：git clone https://github.com/BVLC/caffe.git 然后在我的Repo里面下载Makefile和Makefile.config来替换原有的。接着就是安装python依赖，这里不要按照其他教程里面的安装官方的caffe/python下的requirement.txt，instead，下载我的，然后运行：sudo pip3 install --upgrade -r python/requirements_python3.txt 后面的requirements_python3.txt也可以从上面的Repo下载。接着直接安装就行了：make all -jmake pycaffe 测试一下是否安装成功：./data/mnist/get_mnist.sh./examples/mnist/create_mnist.sh./examples/mnist/train_lenet.sh 如果成功你就会看到caffe在训练mnist了，大概几千次之后准确度就可以达到99%，非常好。 Caffe生成并训练自己的数据集本教程所有的代码，文件目录结构可以在我的github上下载，点这里,下载之后你会看到一个完整的caffe训练架构，但是数据还得另外下载，我在这里只是上传了5类图片的样张图片，真正的数据集大概有600张的样子。下载地址为这里。接下来要生成caffe需要的数据了，步骤如下，大家先不要方，生成数据是整个过程最复杂的部分，不过这个部分也不是很麻烦，我精简一下步骤： Step 1 Generate the image name file Run caffe_path_gen.py in your terminal, just type:python3 caffe_path_gen.py -train=/home/jfg/caffe_tiny5/tiny5/train -shuffle=True -shuffle is optional, because caffe can do this too.In this tutorial we only have train data in image_data folder, we don’t have test image, so we just generate the train image path, and manully divide them into train and test. But if you have test data folder, you also can type:python3 caffe_path_gen.py -train=/home/jfg/Documents/PythonSpace/caffe_tiny5/tiny5/train -test=/home/jfg/Documents/PythonSpace/caffe_tiny5/tiny5/test -valid=/home/jfg/Documents/PythonSpace/caffe_tiny5/tiny5/valid the valid data only generate image path without labels.After this, you gonna have train.txt, words.txt. Step 2 Split train.txt into to train.txt and test.txt Before split please remove the path just make it like this:/flower/683.jpg 3/bus/334.jpg 0/bus/336.jpg 0/dinosaur/481.jpg 2/dinosaur/436.jpg 2/bus/327.jpg 0/elephant/595.jpg 4/bus/357.jpg 0/bus/393.jpg 0/bus/375.jpg 0/dinosaur/453.jpg 2/flower/654.jpg 3/dinosaur/491.jpg 2/bus/365.jpg 0/flower/636.jpg 3/flower/629.jpg 3/bus/347.jpg 0/bus/398.jpg 0/horse/761.jpg 1/elephant/560.jpg 4/dinosaur/449.jpg 2/elephant/531.jpg 4/horse/794.jpg 1/horse/743.jpg 1/elephant/586.jpg 4 But stay with the class prefix Step 3 Generate Caffe LMDB data fileFirst mkdir a data folder just inside the project directory, and place train.txt and test.txt into it.And then open caffe_create_lmdb.sh and just edit the following two lines:TRAIN_DATA_ROOT=/home/jfg/Documents/PythonSpace/caffe_tiny5/tiny5/trainVAL_DATA_ROOT=/home/jfg/Documents/PythonSpace/caffe_tiny5/tiny5/valid 在这一步中，确保TRAIN_DATA_ROOT和上面的train.txt中的文件名能够组成完整的路径即可。 Simply edit two lines, leave other along.Then type:bash caffe_create_lmdb.sh Tip: Anything wrong, check you mkdir a data folder, and have train.txt and test.txt in it.OK, after this, you gonna have two new folder in your data folder, that is:caffe_train_lmdbcaffe_val_lmdbthis is what we need to feed into caffe net and it is nothing with your original image anymore! It’s complete and clean! Do not warry about path wrong anymore! Very nice! Step 4 Generate Mean Binary FileThis step is very easy, don’t change anything ,just type this in your terminal:bash caffe_make_mean.sh And you gonna have caffe_mean.binaryproto file in your data folder. 开始Caffe训练you already have your data, just finish 80% work. 20% to go. Next, we gonna using solver folder. In this folder we have a solver.prototxt and a train_test.prototxt.solver.prototxt is the net pramas setting file.train_test.prototxt is the net structure setting file and your lmdb data feed into net in here.layer &#123; name: \"cifar\" type: \"Data\" top: \"data\" top: \"label\" include &#123; phase: TRAIN &#125; transform_param &#123; mean_file: \"/home/jfg/caffe_tiny5/data/caffe_mean.binaryproto\" &#125; data_param &#123; source: \"/home/jfg/caffe_tiny5/data/caffe_train_lmdb\" batch_size: 100 backend: LMDB &#125;&#125;layer &#123; name: \"cifar\" type: \"Data\" top: \"data\" top: \"label\" include &#123; phase: TEST &#125; transform_param &#123; mean_file: \"/home/jfg/caffe_tiny5/data/caffe_mean.binaryproto\" &#125; data_param &#123; source: \"/home/jfg/caffe_tiny5/data/caffe_val_lmdb\" batch_size: 100 backend: LMDB &#125;&#125; This 2 layer is data feed layer, so you have to change your data path in here.Make sure it correct.Open solver.prototxt, find this 2 and edit it:net: \"/home/jfg/caffe_tiny5/solver/caffenet_train_valid.prototxt\"snapshot_prefix: \"/home/jfg/caffe_tiny5/model/caffenet\" net: it is your train_test.prototxt file postion, snapshot_prefix is your save model path and prefix name, we place all saved models into a model_snapshot folder with prefix cifar10. 训练只需要一行命令：bash train_caffe.sh 重点来了，得到模型之后怎么预测这里我们使用python接口，直接上代码吧，实际上该的地方也不多：# !/usr/bin/env python# -*- coding: utf-8 -*-\"\"\"caffe_test.pyhttp://www.lewisjin.coding.me~~~~~~~~~~~~~~~This script implement by Jin Fagang.: copyright: (c) 2017 Didi-Chuxing.: license: Apache2.0, see LICENSE for more details.\"\"\"import numpy as npimport sysimport osimport cv2caffe_root = '/home/jfg/caffe/'sys.path.insert(0, caffe_root + 'python')import caffenet_file = '/home/jfg/Documents/PythonSpace/caffe_tiny5/solver/caffenet_deploy.prototxt'caffe_model = '/home/jfg/Documents/PythonSpace/caffe_tiny5/solver/model/caffenet_iter_4500.caffemodel'mean_file = '/home/jfg/Documents/PythonSpace/caffe_tiny5/data/caffe_mean.binaryproto'print('Params loaded!')caffe.set_mode_gpu()net = caffe.Net(net_file, caffe_model, caffe.TEST)mean_blob = caffe.proto.caffe_pb2.BlobProto()mean_blob.ParseFromString(open(mean_file, 'rb').read())mean_npy = caffe.io.blobproto_to_array(mean_blob)a = mean_npy[0, :, 0, 0]print(net.blobs['data'].data.shape)transformer = caffe.io.Transformer(&#123;'data': net.blobs['data'].data.shape&#125;)transformer.set_transpose('data', (2, 0, 1))transformer.set_mean('data', a)transformer.set_raw_scale('data', 255.0)transformer.set_channel_swap('data', (2, 1, 0))test_img = 'elephant.jpeg'im = caffe.io.load_image(test_img)net.blobs['data'].data[...] = transformer.preprocess('data', im)predict = net.forward()names = []with open('words.txt', 'r+') as f: for l in f.readlines(): names.append(l.split(' ')[1].strip())print(names)prob = net.blobs['prob'].data[0].flatten()print('prob: ', prob)print('class: ', names[np.argmax(prob)])img = cv2.imread(test_img)cv2.imshow('Image', img)cv2.waitKey(0) OK，本教程到此结束，欢迎乘坐本次老司机列车。这几天一直没有更新博客不是没有写，而且写了没有上传，还是得发时间整理整理，笔耕不啜才是一代文豪应该做的事情啊。 近期计划这是一个花絮，最近我还是决定干点事情了，接下来我会研究一下如何用目标检测算法来识别交通信号灯，这个在无人驾驶领域是肯定会遇到的一个问题，具体来说它有几个难点： 检测信号灯的位置 要检测信号灯就需要训练图片，标注信号灯的方框，这个好办，现有的网络可以做到很好，接下来有个问题就是第二个点。 检测信号等每个路口转向的信号等情况 比如我检测到了信号灯，但是这个信号灯是左转通行还是右转通行呢？是左转通行直行禁止右转禁止还是其他情况呢？而且我检测算法可能在一个视角中检测多个红绿灯，但是我真正感兴趣的只是我前方的红绿灯，那么如何来却分识别出来的红绿灯也是个问题。 这两个问题如何解决还得看数据标注的情况。","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/深度学习/"}]},{"title":"Shell program from newbie to give up series","slug":"2017-1-17-Shell编程从入门到放弃系列","date":"2017-02-01T12:31:45.000Z","updated":"2017-02-03T02:51:25.000Z","comments":true,"path":"2017/02/01/2017-1-17-Shell编程从入门到放弃系列/","link":"","permalink":"http://yoursite.com/2017/02/01/2017-1-17-Shell编程从入门到放弃系列/","excerpt":"","text":"Shell program from newbie to give up series This is a tutorial about shell program, powerful and faster your work on anywhere, so learn it hard, once you handler it, you can become a geek. If you have any question about this post, you can contact me via wechat: jintianiloveu , if you repost please stay with this copyright annoncement, enjoy :) Chapter 1 File Relatedok, in this chapter, the most important and you maybe face with most is file process, such as walk an directory or get all file names in a folder etc. Here I am going write down some useful shell commonds that will hopefully faster your work, even every faster ever than you think. get all files and directoriesHere is one single script:# !/bin/bashfor file in ~/home/datado echo $&#123;file&#125;done That’s it, you can access every file in a directory, if you want get both file and dirs, try this:all=`ls ~/home/data`for f in alldo if [ -d $f ]; then echo $&#123;f&#125;\" is a directory\" else echo $&#123;f&#125;\" is a file\" fi file names and path relatedMost of the time we are annoying with file names and path, sometimes we want get the file name and another time we want the path. So here you cant use 2 powerful commod to solve all problems. They are basename and dirname. Look this example: cycle all names under an (or 2) folderThis is a very instresting question. for item in .. this style is very usefule but we can’t cycle 2 items at the same time, indeed we will have this inquirement sometimes. Here I am going solver this using an example:concate 2 folder’s file names into a txt file, say, folder1 have 1.jpg 2.jpg …, and folder2 have 1.txt 2.txt 3.txt…we gonna generate a txt file like this: 1.jpg 1.txt2.jpg 2.txt... abviously, we have to cycle 2 elements at same time. But! For now we have no method to cycle 2 items in for..in.. So we have to change our plan:We can store the ls |grep &#39;^-&#39; out put into array or list, so we can get them in one for cycle. Here is the script:j=0for img in `ls $&#123;data_root_dir&#125;/Images|sort -h`do img_list[$&#123;j&#125;]=$&#123;img&#125; ((j++))donek=0for label in `ls $&#123;data_root_dir&#125;/Labels|sort -h`do label_list[$&#123;k&#125;]=$&#123;label&#125; ((k++))doneecho $&#123;img_list[0]&#125;echo $&#123;label_list[0]&#125;for ((i=1;i&lt;=$&#123;#img_list[@]&#125;;i++))do echo $i left=$&#123;img_list[i]&#125; right=$&#123;label_list[i]&#125; echo $&#123;left&#125;\" \"$&#123;right&#125;done This code is a little dumped, but I think you can quite get what this means. Chapter 2 About txt file processtxt file is the most simple and wide-use file format, handler how to operate them will gaintly faster your work, and make you seems like a god! Witre lines into txt fileThis is the most basic part of all jobs, and still, the most important. This 2 commond you must remember into your heart:echo \"Hello, world.\" &gt; ~/data/test.txtecho \"Hello, world.\" &gt;&gt; ~/data/test.txt&gt;: ~/data/test.txt first line: overwrite a string into a filesecond line: add a line into a filelast line: truncate all content in a text fileAbove is all the basic commond you have to handler, is simple yet powerful! Generate a random arrayok, another useful general commond that you maybe use all the time, but I think this is not the most simplest way to do this, the purpose is generate a random int array, so that use this we can shuffle txt lines or other things, here is the script:length_imgs=570arr=(`seq $&#123;length_imgs&#125;`)for ((i=0;i&lt;10000;i++))do let \"a=$RANDOM%$&#123;length_imgs&#125;\" let \"b=$RANDOM%$&#123;length_imgs&#125;\" tmp=$&#123;arr[$a]&#125; arr[$a]=$&#123;arr[$b]&#125; arr[$b]=$tmpdoneecho $&#123;#arr[@]&#125; if we get this random array, we can read random lines into a new txt file , liek this:boundry=20for i in $&#123;arr[@]:$&#123;boundry&#125;&#125;do sed -n \"$&#123;i&#125;p\" test.txt &gt;&gt; newtest.txtdone It’s simple enough! Now we have some random lines in newtest.txt Cut stringVery important part, to cut a string whatever we want is a very useful commond! And what you need is only one single cmoond cut. Chapter 3 About MathmaticWell, I have to say this part is a litter complicated, onething you must take in your mind is that Shell Does Not Support Decimal Calculate, though we still can find some method to approach our goal, one properly method is awk.If you want to calculate 0.8x6 , you probbly can do those: $((0.8*6)) echo expr 0.8*6But you wont get what you want, because shell doesn’t support it. But hopefully you can do this:echo | awk '&#123;print 0.8*6&#125;' you will got 4.2","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/深度学习/"}]},{"title":"Django 5 nginx gunicorn以及django的三兄弟","slug":"Django-5-nginx-gunicorn-make-django-project-on-cloud","date":"2017-02-01T06:14:42.000Z","updated":"2017-02-02T06:45:06.000Z","comments":true,"path":"2017/02/01/Django-5-nginx-gunicorn-make-django-project-on-cloud/","link":"","permalink":"http://yoursite.com/2017/02/01/Django-5-nginx-gunicorn-make-django-project-on-cloud/","excerpt":"","text":"本文将介绍使用nginx和gunicorn搭建我们的django服务器，直接把应用上云！ 废话不多说，开车前系紧安全带首先还是啰嗦一句把，在选择一个web容器的时候我们要选择一对好兄弟，很显然，nginx的大名世人皆知，当然我之前一只听说的是apache，不过apache和java可能搭配的更多，nginx呢和django可以说是一对搭档很好的兄弟，nginx在处理静态请求方面的性能很屌，那么问题来了，动态处理是用uwsgi呢还是gunicorn呢，我选择了gunicorn，为什么呢？因为这个名字听起像个gay。既然是gay了那应该可以和django好好的搞基.. 安装nginx好了，直接安装nginx把，这个nginx不像其它容器庞然大物，显得很小，ubuntu下直接：sudo apt install nginx 启动nginx服务器sudo /etc/init.d/nginx start# or this commandsudo service nginx start 请注意，nginx的配置文件是在这个目录里面cd /etc/nginx 如果是Mac，则默认的nginx安装目录应该是：/usr/local/opt/nginx 要启动nginx，这也即可：sudo nginx 即可。Mac下的nginx，配置文件目录在这里：/usr/local/etc/nginx 无论是ubuntu还是Mac，nginx的配置都在 ／etc/nginx 下面，只是ubuntu直接在这下面，Mac放到了/usr/local下面 TIPS: nginx在ubuntu下默认监听的是80端口，而在mac下监听的是8080端口，因此你在ubuntu下测试nginx的欢迎页面时，可能只需要输入localhost即可，但是在mac下你必须要加上8080端口号，注意80是系统默认的监听端口，如果你要修改ubuntu下的监听端口号，比如改成8080，那么你就需要修改/etc/nginx/sites-available下的default文件，不过事先还是先备份一下原来的那个。 最后插播一个东西，vim有时候你没有sudo打开需要权限的文件，改完了之后才发现要权限，然后退不出来，退出来了改完的文件就没有了，相当的蛋疼，这个时候你就需要使用这条命令：:w !sudo tee % 不过要注意空格不能少，而且sudo要紧跟在感叹号后面，就这也就可以保存了。最后补充一句，ngxin在Mac下和ubuntu下配置还是略有不通，ubuntu在／etc/nginx/sites-available/文件夹下有单独的配置文件来配置监听端口，而mac下是直接集成到了/usr/local/etc/nginx下的nginx.cnf中。 配置一下gunicore首先在运行gunicore之前我们要配置一下django工程下的静态文件的路径，也就是STATIC_URL and STATIC_ROOT 这俩个变量，直接在setting.py下面设置：STATIC_ROOT = os.path.join(BASE_DIR, 'static')STATIC_URL = '/static/' 然后还有一件事情，在工程中运行：python3 manage.py collectstatic 这个命令会在工程根目录下生成一个static目录，并把所有的静态文件放在这下面，不过说实话如果你的django工程是一个移动app的服务器而不是网页的话，这个可能没有多大的作用，如果是网页这就直接影响到你网页的css等文件的正确加载了，一定不要忘记这个步骤。 这次我们来测试一下gunicore对我们django的支持怎么样，其实说白了，gunicore就是代替django原生的那个小服务器的作用。但是实际生成中肯定不能用那个小服务器，还是让更加专业的gunicore来把。运行：gunicore --bind 0.0.0.0:8000 yourdjangoprojectc.wsgi:application 这个命令就和python3 manage.py runserver是一样的。 OK！准确的说你已经完成了django的上线准备！nginx准备就绪，gunicore准备就绪！ Django大兄弟，上天吧这个教程就到这里吧，到现在才发现搭建nginx和gunicorn并没有那么简单，为此我会单独开一个post了记录这个过程。除此之外呢，基本上下个过程就是你想要的啦，保证可以学会nginx和python web环境搭建。","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"}]},{"title":"Ubuntu下用Clion和C++开发OpenCV程序教程","slug":"2017-1-6-OpenCV-Clion-C++-开发环境搭建教程","date":"2017-02-01T02:31:45.000Z","updated":"2017-02-03T02:51:32.000Z","comments":true,"path":"2017/02/01/2017-1-6-OpenCV-Clion-C++-开发环境搭建教程/","link":"","permalink":"http://yoursite.com/2017/02/01/2017-1-6-OpenCV-Clion-C++-开发环境搭建教程/","excerpt":"","text":"Ubuntu下用Clion和C++开发OpenCV程序教程 本教程作者是在读硕士金天童鞋，在当地较为英俊的男子，大家对教程有任何疑问欢迎联系我：WeChatjintianiloveu，同时也欢迎大家转载评论，不过请保留这段版权信息，桑口～ 前言在开车之前必须要扯几句，好多天没有更新博客，你在我的官网，或者简书上都看不到我最近的活动，最近在忙着搞无人驾驶，虽然官方博客没有更新但是在github上却有很多小项目，首先放出我的github地址，这里，这几天写了一个爬虫爬取12306网站的脚本，直接在terminal显示余票信息，并可以智能提醒你余票，过年了，有想玩的同学们可以star一下我的这个项目12306爬虫欢迎大家star，多多益善啊我的星星实在是太少了。好了不扯淡了，蛋也快碎了。让我们直接开车吧。 OpenCV在Ubuntu下安装这个大家可以去我前几篇博客上找一下，我写了一篇较为详细的OpenCV3.1编译的文章，总的来说，在Ubuntu下编译比较简单，直接clone项目，设定cmake参数，直接make all -j8就行了，然后install。这里简要lveguo（我打不出那个字，日了狗了）。 Clion上手Clion是Jetbrain公司开发的C++IDE，秉承了Jetbrain一系IDE美观强大的风格，比其某VC，某Qt，某CMake强大很多，然而要上手对于新手来说还是有点麻烦，首先就是这个CMakelists，你不知道怎么配置，太鸡巴麻烦了，我配置了一下午，TMD，真的是日了藏獒，后来发现还是人家OpenCV好，实际上OpenCV已经把CMakelist的样本放到了example文件夹下，我TM是当时瞎了够眼，没有看到，最后灵机一动，突然想起来，发现还真的有。 Clion配置CMakelists.txt来导入OpenCV怎么说，貌似你不在CMakelists里面导入OpenCV相关包你是无法通过编译的，会报错，先话不多说，加入你新建了一个Project叫做VisionTest,下面的主函数cpp名字叫做main，那么CmakeLists.txt这么配置：cmake_minimum_required(VERSION 3.6)project(VisionTest)find_package(OpenCV REQUIRED)message(STATUS \"OpenCV library status:\")message(STATUS \" version: $&#123;OpenCV_VERSION&#125;\")message(STATUS \" libraries: $&#123;OpenCV_LIBS&#125;\")message(STATUS \" include path: $&#123;OpenCV_INCLUDE_DIRS&#125;\")include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)set(CMAKE_CXX_STANDARD 11)set(SOURCE_FILES main.cpp)add_executable(vision_test main.cpp)target_link_libraries(vision_test $&#123;OpenCV_LIBS&#125;) 这里有个重点，最后两行一定要有，而且顺序不能变，这是告诉Cmake，你把main.cpp编译成了一个可执行文件vision_test,然后你要让这个可以执行的文件去连接OpenCV的动态库，如果你在没有add_executable就去添加链接就会报错。谨慎啊，少年，小心使得万年船啊！ C++ OpenCV测试程序示例OK，现在我们配置了Cmake，接下来在main.cpp中输入以下代码：#include &lt;iostream&gt;#include &lt;vector&gt;#include \"opencv2/core/core.hpp\"#include \"opencv2/opencv.hpp\"#include \"opencv2/highgui/highgui.hpp\"using namespace std;int main() &#123; cout &lt;&lt; \"Hello, this is opencv tutorial.\" &lt;&lt; std::endl; cv::Mat img = cv::imread(\"/home/jfg/Pictures/cat.jpeg\"); cv::namedWindow(\"Window\", CV_WINDOW_AUTOSIZE); cv::imshow(\"Cat\", img); cv::waitKey(0); return 0;&#125; 这是一个简单的OpenCV测试程序，要注意的一点是，图片的路径要使用绝对路径，不要使用相对路径，否则会出错。 OpenCV MoveOn其实写这个博客的目的并不是上手OpenCV，基于Linux来做OpenCV编程是因为，我想让OpenCV和硬件结合起来，最理想的方案就是树莓派了，这样通过Linux系统我们就可以让上位机和下位机连接起来，使用这个再加上独门绝迹，深度学习目标检测以及表情识别，想想还是很6的！！ 人工智能机器人Teroi我决定把我的第一台人工智能机器人名字叫做Teroi，意思是：The Emotional Robot Improved.大家觉得怎么样？","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/深度学习/"}]},{"title":"Django 4 django和postgreSQL","slug":"Django-4-django和postgreSQL","date":"2017-01-26T10:41:45.000Z","updated":"2017-02-02T13:23:06.000Z","comments":true,"path":"2017/01/26/Django-4-django和postgreSQL/","link":"","permalink":"http://yoursite.com/2017/01/26/Django-4-django和postgreSQL/","excerpt":"这个教程是要换数据库了，从mysql换到postgresql。说实话我个人以后决定使用postgresql，比mysql方便很多。","text":"这个教程是要换数据库了，从mysql换到postgresql。说实话我个人以后决定使用postgresql，比mysql方便很多。 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu。 postgresql安装教程在这插入一下安装过程，之前安装了现在又重新搭建一遍所以记录一下，其实不管是Mac还是Linux都很简单，直接安装：# macbrew install postgresql# ubuntusudo apt install postgresql 当然除了安装数据库之外，还要安装我们需要的python适配器，从而在django中可以调用它，这里我们安装在virtualenv中把，但是之前一直没有用这个，现在也赶一下时髦用一下，其实大家如果不习惯用的话也没有关系，可以直接安装在系统的python目录下。pip3 install psycopg2 这个包是django用来和postgresql通信的python包，如果不安装的话会报错提醒你的。注意在这里django默认使用了pillow来处理图片，因此在安装psycopg2的时候可以顺便把pillow安装一下，搞深度学习的应该都知道这个包，也就是python3下的pil。pip3 install pillow postgresql一分钟入门前几个教程一直是灌输mysql和django的知识，两个人其实配合的很好，今天突然来了第三者，大家可能会有点接受不了。容我解释一下，首先我觉得到目前为止转换的成本其实是很低的，你只需要卸载mysql，重新安装postgresql就可以了。所有的数据都还不多，无所谓。这里说明下我最终选择postgresql的原因： 安装简单，没有复杂的密码，访问数据库和表简单 开源就不说了 和django搭配很友好，django其实官方是支持postgresql的 最后还有一个很重要的原因就是：尼玛，sb mysql mac下每次重启系统就重置密码是鸡巴几个意思，shit，气得我直接抛弃了这个二笔 。 postgresql简单实用教程：# 创建一个用户sudo -u postgres createuser --superuser jfg# 以postgres身份进入postgresql控制台sudo -u postgres psql# 新建一个数据库sudo -u postgres createdb -O jfg oumenglite 执行上面这些命令你可能觉得一头雾水，下面是postgresql的几条设计逻辑： postgresql是系统级的认证，就是你系统的用户名如果和postgresql用户名相同，则postgresql就不会进行第二步验证 postgresql实行的是每个数据库不同管理员制，也就是说你可以为每个数据库单独设置管理员 好了了解了上面两条逻辑，下面运行和几个命令，首先我们创建一个和当前系统用户名相同的postgresql用户，创建完之后你的系统用户就是postgresql的超级用户，不用指定用户也不用输入密码，方便快捷：sudo -U postgres createuser --superuser yoursysusername 这样你就可以直接输入psql来操作数据库了。 [UPDATE 2017-02-1] 更官方的的postgresql使用应该是这样的，你安装完之后会有一个默认的用户postgres，然后：sudo su postgrescreateuser --interactive -P 这是会提示你创建一个新的用户，然后：createdb --owner yourjusttypename databasename django和postgresql之歌现在django之歌要改成django和postgresql之歌了。我们所有的数据都将基于postgresql来构建，我们插入几条数据来看看显示效果：from users_user; 1 | 金天 | 男 | 1993-12-11 | | | | lewisjin@outlook.com | | | 长沙 | 2 | 小芳 | 女 | 1993-12-11 | | | | xiaof@qq.com | | | 北京 | 3 | 刘明 | 男 | 1993-12-11 | | 浙江 | 15116378920 | xiaof@qq.com | | | 北京 | 感觉数据多的情况下，postgresql的控制台显示效果都比mysql的好，而且你上手postgresql只需要知道这么几条命令就够了：# 新建数据库createdb ara# 选择数据库psql ara# 显示所有数据库psql -l# 显示数据库下的所有表\\d 就是这么simple。你已经从mysql转移到了postgresql！ django继续我们的api时隔很久了，这个教程只要继续我们的django代建restful api的伟大事业。","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"}]},{"title":"Django 3 分分钟搭建一个RESTful API","slug":"Django-3-分分钟搭建一个RESTful-API","date":"2017-01-16T15:31:58.000Z","updated":"2017-01-26T10:42:16.000Z","comments":true,"path":"2017/01/16/Django-3-分分钟搭建一个RESTful-API/","link":"","permalink":"http://yoursite.com/2017/01/16/Django-3-分分钟搭建一个RESTful-API/","excerpt":"","text":"Django restframework 简介时间过得好快，不知不觉这就是Django系列教程的第三部分了，这部分我们将在一分钟之内用django的一个第三方框架-Django restframework搭建我们的第一个api。首先闲话不多说让我们先安装一下这个框架：sudo pip3 install django-restframework ok，安装完之后能让我们新建一个project吧django-admin startproject ara 接着新建一个app：python3 manage.py startapp users ok这时候我们的项目结构应该是这样的：.├── ara│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── users ├── __init__.py ├── admin.py ├── apps.py ├── models.py ├── tests.py └── views.py ok，简单易懂，接着还是我们配置一下restframework吧 Restframework配置配置这个框架请依照这个步骤来，缺一不可： 在settings.py中我们install一下 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'users', 'rest_framework'] 在settings.py中添加这个 # using rest_framework setting this lineREST_FRAMEWORK = &#123; # Use Django's standard `django.contrib.auth` permissions, # or allow read-only access for unauthenticated users. 'DEFAULT_PERMISSION_CLASSES': [ 'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly' ]&#125; ok，经过这个配置之后，我们就可以在项目中import restframework了。接下来我要向同志们展示一下这个东西到底有多么吊炸天！ 三步搞定一套API，增删改查！我说过只用三步，那我们就分三步来。 第1步： 当然是新建一个models 二话不多说直接复制粘贴代码：# -*- coding: utf-8 -*-from django.db import models# Create your models here.class User(models.Model): \"\"\" name: name of user, gender: user's gender wechat: user's wechat \"\"\" name = models.CharField(max_length=100, blank=False) gender = models.CharField(max_length=4, blank=True) birthday = models.DateField(blank=True) portrait_url = models.CharField(max_length=100, blank=True) home = models.CharField(max_length=20, blank=True) phone = models.CharField(max_length=17, blank=True) email = models.CharField(max_length=20, blank=True) wechat = models.CharField(max_length=20, blank=True) company = models.CharField(max_length=20, blank=True) occupation = models.CharField(max_length=20, blank=True) living_city = models.CharField(max_length=20, blank=True) def __str__(self): return self.name 第2步： 在app下新建serializers.py，写入这些代码 二话不多说直接复制粘贴代码：from rest_framework import serializers, viewsetsfrom users.models import Userclass UsersSerializer(serializers.ModelSerializer): class Meta: model = User fields = '__all__'# ViewSets define the view behavior.class UsersViewSet(viewsets.ModelViewSet): queryset = User.objects.all() serializer_class = UsersSerializer 在这里我们实现一个UsersSerializers以及一个UsersViewSet这两个类，这个序列化函数暂且不知道是干毛的，但是很显然这个函数的作用是把从数据库中查询的结果序列化为字符串。不过重点是这个ViewSet，这个东西就这么几行代码它就帮你实现好了增、删、改、查的所有功能。不是吹牛逼等一下我们来验证看看是不是。你会惊奇的发现，有了这个ViewSet之后我们都不用写view.py了！！！！！ 第3步： 配置urls二话不多说直接复制粘贴代码：from django.conf.urls import url, includefrom django.contrib import adminfrom users.serializers import UsersViewSetfrom rest_framework import routersrouter = routers.DefaultRouter()router.register(r'api/v1/users', UsersViewSet)urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')), url(r'^', include(router.urls))] 配置urls要用到restframework中的router这个类，这个是一个路由器，或者说是分发器，request的网址分发过来我发给哪个view处理就有他来决定，但是很显然这里并没有发给任何一个view，而是直接发给了一个ViewSet，这个ViewSet结合我们的serializer就可以实现我们的返回json或者接受json的全套功能！就是这么的屌！屌的爆炸！！好吧，最后说一下urlpatterns里面的几个pattern，第一个是admin不需要多说，重点是最后一个我们include了router的urls，所以说你只需要按照router的网址来写即可，不过重点是router还实现了一个隐士查询也就是你可以加具体数字查询具体的detail。 Django restframework测试！说了这么多来测试一下呗！！我们输入：http://127.0.0.1:8000/api/v1/users 看看返回的结果：HTTP 200 OKAllow: GET, POST, OPTIONSContent-Type: application/jsonVary: Accept[ &#123; \"id\": 1, \"name\": \"金天\", \"gender\": \"男\", \"birthday\": \"1993-12-11\", \"portrait_url\": \"https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1593523098,2479335990&amp;fm=116&amp;gp=0.jpg\", \"home\": \"江西南昌\", \"phone\": \"15116123160\", \"email\": \"1195889656@qq.com\", \"wechat\": \"jintianilveu\", \"company\": \"\", \"occupation\": \"\", \"living_city\": \"\" &#125;, &#123; \"id\": 2, \"name\": \"Elgins\", \"gender\": \"男\", \"birthday\": \"1994-11-02\", \"portrait_url\": \"\", \"home\": \"\", \"phone\": \"\", \"email\": \"\", \"wechat\": \"\", \"company\": \"\", \"occupation\": \"\", \"living_city\": \"\" &#125;] 在网页中你可以直接测试POST PUT GET等方法，总是很牛逼有没有！！分分钟做一套API啊！！比java web快出了不知道多少倍！！！明天我们继续深入探测这个东西！！！！！","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"}]},{"title":"Django 2 MySQL and Blog","slug":"Django-2-MySQL-and-Blog","date":"2017-01-15T10:14:45.000Z","updated":"2017-01-26T10:42:12.000Z","comments":true,"path":"2017/01/15/Django-2-MySQL-and-Blog/","link":"","permalink":"http://yoursite.com/2017/01/15/Django-2-MySQL-and-Blog/","excerpt":"","text":"mysql usageIn this post I am going writting some useful commonds of mysql, hand this you can operate Database as cake. Change specific database encode ALTER DATABASE ara CHARACTER SET utf8; Change all database encode SET CHARACTER_SET_CONNECTTION=utf8;SET CHARACTER_SET_DATABASE=utf8;SET CHARACTER_SET_SERVER=utf8;SET CHARACTER_SET_CLIENT=utf8; Ultimate method to change encode of mysqlok, I have to admmit that above method you cannot really change mysql’s encode, it still be latin1 for character_database and character_server. But using this you can change the encode method forever. First of all, please make sure you have stop mysql.Step 1copy my-default.cnf to /etc/my.cnf, using: cp /usr/local/mysql/support-files/my-default.cnf /etc/my.cnf Step 2changing a exactly right to that file, make sure only you can write and read it, using:sudo chmod 644 my.cnf Step 3add this lines to the file:sudo vim my.cnf [client]default-character-set=utf8 under [mysqld] adding this:default-storage-engine=INNODBcharacter-set-server=utf8collation-server=utf8_general_ci ok, then save and quit, start mysql, and you will find:mysql&gt; show variables like \"%char%\";+--------------------------+---------------------------------------------------------+| Variable_name | Value |+--------------------------+---------------------------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/local/mysql-5.7.16-osx10.11-x86_64/share/charsets/ |+--------------------------+---------------------------------------------------------+8 rows in set (0.01 sec)","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"}]},{"title":"Django 1 Django和mysql","slug":"Django-1-Django上手教程","date":"2017-01-12T12:31:45.000Z","updated":"2017-01-26T10:44:52.000Z","comments":true,"path":"2017/01/12/Django-1-Django上手教程/","link":"","permalink":"http://yoursite.com/2017/01/12/Django-1-Django上手教程/","excerpt":"这个post是讲述django和mysql的故事，记录django常用命令以及mysql的python接口安装方法，环境为python3.6。","text":"这个post是讲述django和mysql的故事，记录django常用命令以及mysql的python接口安装方法，环境为python3.6。 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu。 Django大法作为一位极客，不会点服务端还真不行，现在什么都离不开云啊，最近一直想建站，app接口也要用到云，本来打算用java，可是想了一下java即使使用框架访问数据库的效率还是有点低，而我呢，python玩得这么6，人生苦短啊为何不用python，反正都是事先一样的东西，我们做的也不是淘宝天猫，不需要考虑太多并发的东西，因此从某种意义上来讲，使用django是一个非常不错的选择。好了闲话不多说，这是一个django之歌的系列，既然是歌那就得分乐章，不分逻辑了。 Django命令 [UPDATE] 2017-01-26 python3 manage.py createsuperuser 这个命领用来创建一个django的后台管理员用户名和密码。 Django的安装就不多说了，安装好python，比如mac下brew install pyton3就ok了，再次必须说明一下，我不太喜欢过时的东西，但是太新意味着踩坑，所以大家要做好踩坑的准备。Django安装好之后就可以直接用了，这里我收集一下django入门会用到的命令吧：django-admin startproject deepxpython3 manage.py startapp articlepython3 manage.py runserver 第一个命令是新建项目，第二个新建一个app，这里一个app其实就是项目中的一个功能模块，在我看来。新建好的django一般是这样的工程目录：.├── article│ ├── __init__.py│ ├── __pycache__│ │ └── __init__.cpython-36.pyc│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── lewisblog│ ├── __init__.py│ ├── __pycache__│ │ ├── __init__.cpython-36.pyc│ │ └── settings.cpython-36.pyc│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── manage.py 这里article就是app，lewisblog是整个工程的名字。 Django和mysqlUPDATE这里增加一下，很多人说python3.6 安装mysql报错，解决方法是python3安装mysqlclient，网上很多方法都是过时，其他mysql的驱动并不适用python3，大家注意了啊！可以说这是一对好拍档，很多人说django自带的sqlite就很不错啊，使得sqlite很方便不用安装不用配置，数据库文件就在工程的目录下，访问简单快捷，但是呢，sqlite并太轻了，我们还是使用mysql吧，毕竟比较流行，而且一些语句也是我们常用的语句，因此可以说mysql是非常合适不过的啦。在配置mysql的时候要在上面的settings.py中设置：DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'lewisblog', 'USER': 'root', 'PASSWORD': 'root', 'HOST': '127.0.0.1', 'PORT': '3306', &#125; ok,在这里我们就设置好了数据库引擎以及数据库的名字和密码之类的东西，当然要想链接上数据库还得再mysql中新建则个数据库，数据库名字随便取罗。然后我们要干啥？对了这个settings，在你新建了一个app之后记得在这里登记一下，这里可以控制是哪些app有效。 Django和Model很多人都说DJango是一个template，为什么这么说，思考一下，很多其他库做后台操作数据库都免不了要写一些数据库查询语句，增删改查都要连接数据库查询有没有然后增删改，但是这样做的效率其实是非常低的。很多不必要的操作都是在这里产生的。而Django在这个地方就不同，它自己实现一个很强大的基类，就是model，这就是一个数据库模型，在model里面你可以找到数据库里面的各种数据类型，甚至在时间的操作上比数据库还简单。比如我们要写一个article的表，我们不用再数据库里面建了，建好了然后在写一个数据类，这在java里面你就得干这个脏活，但是在django里你就不需要重复无意义的事情了，你只需要建一个model，然后migrate一下，你就可以在mysql中看到你新建的表了。怎么样方便吧，哎写了这么多肚子有饿了。看来明天得好好吃一顿了。贴一个model新建的类的代码：(在上面的app下面的models.py中)from django.db import models# Create your models here.class Article(models.Model): title = models.CharField(max_length=100, blank=True) category = models.CharField(max_length=50, blank=True) author = models.CharField(max_length=50, blank=True) date_time = models.DateTimeField(auto_now_add=True) content = models.TextField(blank=True, null=True) def __unicode__(self): return self.title class Meta: ordering = ['-date_time'] 看看，所见即所得，你一旦实现了这个model之后你就不用管mysql了，以后插入数据什么的只需要实现这个类就行了，简直是方便的有点蛋疼啊！新建了这个model之后，你要把这个应用到mysql需要下面两条啊语句：python3 manage.py makemigrationspython3 manage,py migrate 第一条意思是我把model在本地生成一个migrations文件夹，里面要记录你对数据的操作，而第二个命令就是你对这个操作施加到数据库中。两条命令按顺序执行才能deploy到数据库里面，这时候打开mysql就可以看到我们的表了：mysql&gt; USE lewisblog;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; SHOW TABLES;+----------------------------+| Tables_in_lewisblog |+----------------------------+| article_article || auth_group || auth_group_permissions || auth_permission || auth_user || auth_user_groups || auth_user_user_permissions || django_admin_log || django_content_type || django_migrations || django_session |+----------------------------+11 rows in set (0.00 sec) 看到没，我们的模型已经转换成表了。6不6！！！ Django的mysql shell其实Django内置了一个shell，在这个shell里面你可以模拟mysql对数据库进行增删改查，但是呢，要进入这个shell还是得默默的进入，不要让任何人知道：python3 manage.py shell 进入shell，这是一个神奇的地方，我们执行以下这个命令：&gt;&gt;&gt; from article.models import Article&gt;&gt;&gt; Article.objects.create(title = 'hello world.', category = 'django', author = 'Lewis Jin', content = 'Today I leared Django and it is very nice!') &lt;Article: Article object&gt; 接着你甚至不用migrate就可以直接在mysql中查看到我们已经成功地添加了一条记录在数据库中！你就说6不6！！mysql&gt; mysql&gt; SELECT * FROM article_article;+----+--------------+----------+-----------+----------------------------+--------------------------------------------+| id | title | category | author | date_time | content |+----+--------------+----------+-----------+----------------------------+--------------------------------------------+| 1 | hello world. | django | Lewis Jin | 2017-01-12 13:25:13.273888 | Today I leared Django and it is very nice! |+----+--------------+----------+-----------+----------------------------+--------------------------------------------+ 这是增，改和删也很简单：&gt;&gt;&gt; a = Article.objects.get(id=1)&gt;&gt;&gt; a.title'hello world.'&gt;&gt;&gt; a.title = 'Hello World'&gt;&gt;&gt; a.title'Hello World'&gt;&gt;&gt; a.delete() 本篇章结语基本上看完这些就可以入门了，接下来我们更加深入的剖析django，我们要充分利用这个利器，来实现我们想要的web程序，让云变的触手可及！！","categories":[],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"}]},{"title":"Mac下安装和使用postgreSQL","slug":"Mac下安装和使用postgreSQL","date":"2017-01-02T07:02:18.000Z","updated":"2017-02-02T13:22:51.000Z","comments":true,"path":"2017/01/02/Mac下安装和使用postgreSQL/","link":"","permalink":"http://yoursite.com/2017/01/02/Mac下安装和使用postgreSQL/","excerpt":"本文介绍Mac下如何对nexus进行刷机，实际上还是非常简单的，10分钟即可搞定，然后就是nexu6的root教程","text":"本文介绍Mac下如何对nexus进行刷机，实际上还是非常简单的，10分钟即可搞定，然后就是nexu6的root教程 本文由在当地较为英俊的男子金天撰写，大家有任何疑问欢迎联系我: jintianiloveu Mac下快速安装postgreSQL开始开车之前我们花一分钟的时间来安装一下这个，说是一分钟实际上一分钟都不需要，如果你是开发者，mac上应该安装了brew吧，我们直接用brew安装。这里多说一句如果你用postgreSQL官网的安装包的话，虽然简单但是你会得到一个全家桶，我建议直接用代码安装，用brew就一行命令：brew install postgresql 简单方便快捷，等一下我对比一下mysql和postgresql的上手难易度，你会发现mysql like a shit，尤其是在mac上，我曹，鸡巴不知道哪里好端端的就会出问题。好了不多说了，安装好了测试一下：新建一个数据库：createdb mydb 访问这个数据库pslq mydb 这样你就完成了postgresql从入门到精通了。 为什么是postgreSQL而不是MySQL？在选择数据时其实是一个很重要的问题，当然如果你是一个高手，任何数据库应该都没问题，但是如果你是入门级的开发者或者是只是用来做产品，那我建议用postgresql。从这个安装和上手步骤你就会发现，postgre更加完美，方便。你甚至不需要关心任何其他的东西。只需要安装，新建数据库，使用它。 postgreSQL逆天功能个人觉得mysql应该退出历史舞台的很大原因是，用的人太多了。大部分还是固守陈旧，而我喜欢简单的东西，什么东西简单就能节省我的时间我会欢迎他，而postgresql说实话，很简单，简单到什么地步，你需要用下面的命令来感受一下： 查看所有数据库psql -l 就是这么简单。 切换数据库\\c newdatabase postgreSQL只是一个工具不过到头来，不管是mysql还是postgresql，都是只是一个工具，我们如何用它来制作我们的产品才是真正重要的东西。毫无疑问，postgresql是django强烈建议的数据库，就单单支持中文编码而言，如果你用mysql你就会遇到很多编码问题，但是pg没有这个问题。接下来我们要用django来搭配postgresql，创造一些产品。","categories":[],"tags":[]},{"title":"Yolo训练自己的数据集教程 Newest(2016-12-23)","slug":"Yolo训练自己的数据集教程-Newest-2016-12-23","date":"2016-12-22T10:27:38.000Z","updated":"2017-02-02T06:04:53.000Z","comments":true,"path":"2016/12/22/Yolo训练自己的数据集教程-Newest-2016-12-23/","link":"","permalink":"http://yoursite.com/2016/12/22/Yolo训练自己的数据集教程-Newest-2016-12-23/","excerpt":"yolo教程","text":"yolo教程 Yolo darknet训练自己的数据集教程(Newest 2016.12.23) 经过两天的折腾终于搞定了Yolo训练自己的数据集的过程，整个过程其实并不繁琐，只是网上一些过时的教程已经不适用了，依照那个反而让大家各种出出错，加之Yolo中文教程过少，因此本大神再次放一个，如果大家有任何问题直接在文章后面评论即可，笔者看到之后给予第一时间回复。 先插一句，Atom中文不能跟随窗口wrap文字的同学，打开settingview，设置soft wrap即可，百度上的答案真的是渣 Yolo简介在训练数据集之前，相信大家对yolo应该有一些了解，本文所采用的测试环境为：Ubuntu 16.04 + opencv2.4 + cuda8 + cudnn5.1 PLUS GTX1080，当然这个硬件不是必须，在下只是偶尔装一下逼。Yolo基于darknet编写，而编译draknet的时候最好安装一下opencv，因为没有opencv图不会自动弹出，没有那种快感，你懂得，不知道如何安装opencv的同学去我之前写的几个博客中搜寻。均能够找到最新的答案。 yolo之所以快，是因为它的方法和fastrcnn以及其他detect算法不同，而采用了很多ssd的思想，在最新的更新中，yolo也改进了他们的算法，在pascal voc数据集上取得了不错的结果。本文将主要利用yolo来做realtime detect，对自己的数据进行训练和预测。 开始开车OK，闲话不多说，让我们直接上车，这次是无人驾驶，速度比较快，大家系好安全带。 Step 1 编译darknet，并熟悉目录结构 第一部分没有什么说的，很简单其实，首先clone代码到本地~目录：cd ~git clone https://github.com/pjreddie/darknetcd darknetmake 这个时候我们在home根目录就有了darknet了。直接编译，不需要修改任何参数，当然如何你是土豪，你有GTX1080,像我一样（手动装比）。可以编译一下Makefile里面的参数。为了防止大家出错我还是说一下，直接改标志为：GPU=1CUDNN=1OPENCV=0DEBUG=0 如果你的cuda没有设置环境变量，nvcc的路径也设置一下：NVCC=/usr/local/cuda/bin/nvcc 不要想的很复杂其实很简单。ok，现在直接make，编译就可以了。 Step 2 准备自己的数据集 好了我们现在有了darktnet，但是我要那个匡出物体的掉炸天的图怎么搞？莫慌，我们先用darknet自带的测试数据来测试一下。首先呢，yolo这个网络是训练VOC数据集得来的，20中物体都能识别出来，我们直接下载已经训练好的权重然后来预测一张图片看看：wget http://pjreddie.com/media/files/yolo.weights 这时候我们就下载好了yolo.weights，在darknet目录下。然后我们就可以用这个权重来预测啦！./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg detect命令意思是，检测，后面还有i一个命令是detector train，后者是训练的命令，预测用detect，cfg/yolo.cfg就是yolo这个网络的结构文件，后面是权重，最后后面是图片。ok，enter你就可以看到狗和自行车了！～这就搞定了darknet，那么问题来了。自己的数据集怎么准备呢？重点来了重点来了： images 准备 首先，把你的图片放到一个/images 文件夹下面，文件名的名字要有规律，比如0001.jpg,0002.jpg….0100.jpg; xml 准备 我相信很多人都需要用图片标注工具来对图片生成标注信息来训练，但是图片标注工具生成的多半是xml的标签信息。darknet需要的label并不是xml格式，而是一张图片一个txt的形式，txt中是你标注的物体方框坐标。后面我会放出几个脚本来处理。 xml 转 darknet label xml转为darknet需要的label形式，一张图片一个标注信息。 生成图片路径最后一部我们要生成两个txt文件，一个是train.txt,一个是valid.txt，train.txt包含了你训练图片需要的图片路径，没一行都是一张图片的路径，为了防止出错，后面我放出一个统一的脚本生成这个train.txt。 Step 3 训练之前修改darknet参数 接下来就要修改darknet的参数了，只要修改/cfg/voc.data 文件，因为yolo是为了voc而存在的，为了不修改源代码的情况下来训练我们的数据，建议直接修改voc.data而不是修改voc.data文件名。修改内容如下：classes= 20train = /home/pjreddie/data/voc/train.txtvalid = /home/pjreddie/data/voc/2007_test.txtnames = data/voc.namesbackup = /home/pjreddie/backup/ 这里，classes就是你数据集的类别，names你的新建一个，在data下面，然后在这里指向它，仿照voc.names 新建即可。修改train.txt valid.txt的路径，用绝对路径哦，防止出错，因为你darknet和数据可能不再一个目录。ok，这就setup完了，接着直接训练。不过训练之前获取一个预处理的权重：curl -O http://pjreddie.com/media/files/darknet19_448.conv.23 然后，train：./darknet detector train cfg/voc.data cfg/yolo-voc.cfg darknet19_448.conv.23 对了，如果你上面改了voc.data的文件名，这里也要改，所以说其实改也是可以的。然后yolo-voc.cfg就可以不改了。 Step 4 yolo训练出的模型预测./darknet detect cfg/yolo-voc.cfg /backup/voc.weights data/sample.jpg 这里不要和直接copy我的代码，cfg/yolo-voc.cfg就是我们训练的网络。后面是训练保存的权重，最后是你要预测的图片。OK，看看结果咋么样～","categories":[],"tags":[]},{"title":"夜有所思","slug":"夜有所思","date":"2016-12-11T15:35:30.000Z","updated":"2016-12-12T02:20:36.000Z","comments":true,"path":"2016/12/11/夜有所思/","link":"","permalink":"http://yoursite.com/2016/12/11/夜有所思/","excerpt":"本文是我的一个随笔","text":"本文是我的一个随笔 你有过思念的感觉吗？ 桃花谢了春红，太匆匆，却是朝来风雨晚来风岁月悄然流淌，我们也在成长，可是在成长的岁月里那些留给我们的感动我们还记得多少呢？以前只有离别家乡的时候才会与依依不舍之情，现在离开的这个地方不是家乡，却有着跟家乡一样的感觉，有着牵挂的人，这也许就是一种魂牵梦绕的情愫吧。今天把博客从实验室搬到了自己的笔记本，宾至如归，所有的事情我都想好好的握在手里，不至于等到失去之后我才后悔莫及。好吧这其实是一个测试，测试一下博客有没有迁移成功，也不能太伤感了，哎。测试一下，再次测试一下！！！","categories":[],"tags":[]},{"title":"git命令删除当前远程仓库依赖","slug":"git命令删除当前远程仓库依赖","date":"2016-12-11T13:51:12.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/11/git命令删除当前远程仓库依赖/","link":"","permalink":"http://yoursite.com/2016/12/11/git命令删除当前远程仓库依赖/","excerpt":"git命令简介","text":"git命令简介 学会使用git命令，不仅仅可以远程操控一切，还可以节省很多体力劳动，比如插优盘拔优盘.. 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ git命令使用简介git命令其实非常简单，但是网上的教程大多数都是乱七八糟，误人子弟，其实要我来讲，只需要记住一个概念：git是将本地仓库对接远程仓库的工具，这里记住有两个名词，一个本地仓库一个远程仓库，那么必然是两个仓库，很多人在后面遇到很多问题都是不明白这两个概念造成的。使用之前首先第一步用git初始化，然后把所有文件添加到本地仓库，注意一定要添加之本地仓库，而在添加本地仓库的时候，如果你的代码有修改，那么就得commit，所谓commit就是执行，确保执行，加上你的注解，防止后面你不知道改了哪个地方。然后才是git remote add origin http://github.com/..最后才是push所以说一般的git使用套路是这样的：git initgit add .git commit -a -m \"first commit\"git remote add origin http://github.com/jinfagang/Morph.gitgit push origin master 注意这里为什么要添加到origin而不是brigin或者其他名字，其实是可以的，只是我们习惯拔本地仓库明明为origin。 git修改远程仓库有时候我们需要修改一下远程仓库的依赖，很简单git remote remove origin 直接拔本地的remote仓库删除即可。","categories":[],"tags":[]},{"title":"Mac下为nexus6刷入官方系统并root","slug":"Mac下为nexus6刷入官方系统并root","date":"2016-12-05T07:02:18.000Z","updated":"2016-12-05T07:47:23.000Z","comments":true,"path":"2016/12/05/Mac下为nexus6刷入官方系统并root/","link":"","permalink":"http://yoursite.com/2016/12/05/Mac下为nexus6刷入官方系统并root/","excerpt":"本文介绍Mac下如何对nexus进行刷机，实际上还是非常简单的，10分钟即可搞定，然后就是nexu6的root教程","text":"本文介绍Mac下如何对nexus进行刷机，实际上还是非常简单的，10分钟即可搞定，然后就是nexu6的root教程 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu 安装adb直接用homebrew安装即可： brew install android-platform-tools 下载google官方镜像这个直接按照链接下载即可，不用担心GFW的问题，貌似下载速度还很快： 最新的7.0系统的下载链接：https://dl.google.com/dl/android/aosp/shamu-nbd91p-factory-987282ff.zip 最新的6.0.1系统的下载链接：https://dl.google.com/dl/android/aosp/shamu-mob31k-factory-49a4de6b.zip 解锁bootloader(如果device是locked状态)关机，按电源键＋音量下开机。在Mac终端上运行 fastboot oem unlock 一键安装将下载的原生系统zip包解压，然后到切换到解压之后的目录，在终端执行 ./flash-all.sh OK，重启既可进入新的系统。 root方法需要下载supersutwrpElementalX","categories":[],"tags":[]},{"title":"Android开车第一弹-MaterialDesign设计规范","slug":"Android开车第一弹-MaterialDesign设计规范","date":"2016-12-04T14:10:02.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/04/Android开车第一弹-MaterialDesign设计规范/","link":"","permalink":"http://yoursite.com/2016/12/04/Android开车第一弹-MaterialDesign设计规范/","excerpt":"本文是Android学的一个随笔","text":"本文是Android学的一个随笔 会iOS再来学Android，一切就像行云流水一样融会贯通，从某种意义上来讲，Android比iOS简单，iOS能够实现更精细的布局，但是也更复杂。Android大条随意，这也是为什么我想学习它的原因。 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 自定义ToolBar 学习Android一个很重要的问题就是自定义一个美观的toolbar，而很多人不懂得设计规范，各种直接拖按钮上toolbar，太猥琐了。人家google明明有标准的规范为什么不用，非得自作聪明的乱加。好了不多说了，自顶一个一个toolbar步骤如下： 更改主题为NoActionBar这是第一步，也是最重要的一步，要用toolbar，首先把Actionbar去掉。去掉的方法也很简单，直接设置styles.xml：&lt;style name=\"AppTheme\" parent=\"Theme.AppCompat.Light.NoActionBar\"&gt; &lt;!-- Customize your theme here. --&gt; &lt;item name=\"colorPrimary\"&gt;@color/colorPrimary&lt;/item&gt; &lt;item name=\"colorPrimaryDark\"&gt;@color/colorPrimaryDark&lt;/item&gt; &lt;item name=\"colorAccent\"&gt;@color/colorAccent&lt;/item&gt; &lt;item name=\"android:actionMenuTextColor\"&gt;@color/colorWhite&lt;/item&gt;&lt;/style&gt; 这样以来又有个问题，这里设置了主题是light，那么toolbar的文字就会变成黑色，我们进一步定义一个toolbar的theme:&lt;style name=\"ToolbarTheme\" parent=\"@style/ThemeOverlay.AppCompat.ActionBar\"&gt; &lt;item name=\"actionMenuTextColor\"&gt;@android:color/white&lt;/item&gt; &lt;item name=\"android:textColorPrimary\"&gt;@android:color/white&lt;/item&gt; &lt;item name=\"android:popupMenuStyle\"&gt;@style/Platform.ThemeOverlay.AppCompat.Light&lt;/item&gt;&lt;/style&gt; 这里定义了toolbar主题的文字颜色。你设置了NoActionbar之后，实际上在AndroidStudio上的designer就没有ActionBar了，还需要从空间中拖入一个toolbar到actiivity_main.xml，这样的话我们就实现了，toolbar。但是只是一个toolbar我们还没有加入menu 添加menu添加menu，先不管代码，新建一个menu的布局文件，直接拖入menu即可，如果你要想menu在toolbar显示呢就设置app:showAsAction=\"always\" AndroidStudio现在有个好处就是都可以直接在界面上设置了，甚至不用写代码。然后我们在activity java文件中写代码：Toolbar toolbar = (Toolbar) findViewById(R.id.toolbar);setSupportActionBar(toolbar); 这两行代码就设置了我们的toolbar为actionbar了。接着处理menu事件，首先导入包：import android.view.Menu;import android.view.MenuItem; 不导入包，ide不会提示你重写哪几个方法。所以还是导入一下比较好。接着我们就可以开车了：public boolean onCreateOptionsMenu(Menu menu)&#123; getMenuInflater().inflate(R.menu.toolbar_menu, menu); return true;&#125;public boolean onOptionsItemSelected(MenuItem item)&#123; switch (item.getItemId())&#123; case R.id.settings: System.out.println(\"====&gt;settings\"); break; case R.id.more: System.out.println(\"=====&gt;more\"); break; case R.id.about: System.out.println(\"====&gt;about\"); break; default: break; &#125; return true;&#125; 这两个方法就可以实现那啥了。 使用recyclerview学习一个移动操作系统必须得学习list的使用，在安卓中就是recyclerview，在iOS中就是tableview和collectionview。扯远了，安卓使用recyclerview其实也是很简单的。 在主界面中拖入一个recyclerview这个不需要多说，有手的人都能托，而且大家的手又都这么健壮… 新建一个recyclerview item的布局文件我不得不说一下安卓跟iOS开发的巨大不同啊，iOS讲究的是精细，美观，所以布局是个很头疼的问题，而安卓就不一样，不管你怎么拖好像它都能帮你自动适配，不过安卓也很难做出iOS那样精细的页面，不过没有关系，好在我们的安卓手机屏幕都很大，加上我们的material design还是非常美观的，也非常符合这种设计语言和风格。、布局文件随便拖入几个控件或者textview，接下来我们就写控制器来控制他们。 写适配器，类似于iOS中的tableviewcellcontroller适配器也很简单，首先你要导入包，否则不会提示你重写的方法。 import android.content.Context;import android.support.v7.widget.RecyclerView;import android.support.v7.widget.RecyclerView.*;import android.view.LayoutInflater; 貌似这些包都要用到。没有关系，接下来我们就重写方法了，一个完整的适配器例子如下：public class RecyclerViewAdapter extends RecyclerView.Adapter&lt;RecyclerViewAdapter.MyViewHolder&gt; &#123; private Context context; private List&lt;String&gt; data; public RecyclerViewAdapter(Context context, List&lt;String&gt; data)&#123; this.context = context; this.data = data; &#125; public RecyclerViewAdapter.MyViewHolder onCreateViewHolder(ViewGroup parent, int viewType)&#123; View view = LayoutInflater.from(context).inflate(R.layout.list_item_layout, null); return new MyViewHolder(view); &#125; public void onBindViewHolder(RecyclerViewAdapter.MyViewHolder holder, int position)&#123; String res = data.get(position); holder.tv1.setText(\"nihao\"); &#125; public int getItemCount()&#123; return 20; &#125; class MyViewHolder extends ViewHolder&#123; TextView tv1; public MyViewHolder(View view)&#123; super(view); tv1 = (TextView) view.findViewById(R.id.textView); &#125; &#125;&#125; 最后一部，找到recyclerview，设置适配器最后一步很简单，直接贴代码了RecyclerView recyclerView = (RecyclerView) findViewById(R.id.recyclerView);ArrayList&lt;String&gt; dataArray = new ArrayList&lt;String&gt;();for (int i = 1; i&lt;50; i++)&#123; dataArray.add(\"hello\");&#125;LinearLayoutManager manager = new LinearLayoutManager(this);manager.setOrientation(LinearLayoutManager.VERTICAL);recyclerView.setLayoutManager(manager);recyclerView.setItemAnimator(new DefaultItemAnimator());RecyclerViewAdapter adapter = new RecyclerViewAdapter(this, dataArray);recyclerView.setAdapter(adapter);","categories":[],"tags":[]},{"title":"mxnet开车教程series1-mnist上手","slug":"mxnet开车教程series1-mnist上手","date":"2016-12-03T13:50:54.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/03/mxnet开车教程series1-mnist上手/","link":"","permalink":"http://yoursite.com/2016/12/03/mxnet开车教程series1-mnist上手/","excerpt":"mxnet入门中文教程，让我们从mnist果蝇数据集开始开车","text":"mxnet入门中文教程，让我们从mnist果蝇数据集开始开车 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 前言最近搭建起了深度学习环境，mxnet被亚马逊钦定为官方的机器学习库，加上mxnet快速，代码清晰的特点，我赶紧乘上了mxnet快车，准备以mxnet为基础开始一些理论研究和产品实现。然而….mxnet搭建过程还是有点麻烦的，尤其是对于对编译过程不是非常熟悉的同学，这一点和caffe有点像，不过这不是问题，在本博客前面几篇文章对此有一个专门的教程，大家可以去看看，欢迎评论转载。这篇文章是mxnet开车教程的第一弹，让我们从果蝇数据集开始下手。 开车！二话不多说，开始开车，作为一名深度学习老司机，我们应该要学会果蝇数据集的正确下载方式，我这里就不贴了，去Lecun的官网下载。下载之后解压，你将会看到四个文件：t10k-images.idx3-ubytet10k-labels.idx1-ubytetrain-images.idx3-ubytetrain-labels.idx1-ubyte 这就是训练集和测试集的数据和标签，很多人一看不知道这是什么鬼，其实我也不知道这是什么鬼，反正是一种文件格式就对了。不多说了直接上代码，开车之前先导入包：import structimport numpy as npimport matplotlib.pyplot as pltimport mxnet as mximport logginglogging.getLogger().setLevel(logging.DEBUG) 哪个包缺少安装哪个，玩mxnet你不要告诉我你还没有安装mxnet，快去我的另外一片博文看教程安装。 读取mnist数据集的正确姿势接下来我有必要传授大家读取mnist数据集的正确方式了，网上流传的各种方法都是瞎扯淡，不懂得科学内涵（手动装逼）。正确的读取方式我谢了两个函数，一个读取label，一个读取image：def read_mnist_label(file_name): bin_file = open(file_name, 'rb') magic, num = struct.unpack(\"&gt;II\", bin_file.read(8)) label = np.fromstring(bin_file.read(), dtype=np.int8) return labeldef read_mnist_image(file_name): bin_file = open(file_name, 'rb') magic, num, rows, cols = struct.unpack(\"&gt;IIII\", bin_file.read(16)) image = np.fromstring(bin_file.read(), dtype=np.uint8).reshape(num, rows, cols) return image 将我们下载的文件传进去，就能得到label，images的输出，应该都是numpy.array的格式。 测试图片我们写个显示图片的函数把：def plot_image(image_array): plt.imshow(image_array, cmap='gray') plt.show() 输入图片矩阵，画出图片。val_img = read_mnist_image('t10k-images.idx3-ubyte')plot_image(val_img[0]) 这就把测试集的第一张图片显示出来了。 搭建mxnet网络这部分直接根据官网的来：batch_size = 100train_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)val_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)data = mx.sym.Variable('data')data = mx.sym.Flatten(data=data)fc1 = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")fc2 = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden=64)act2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")fc3 = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=10)mlp = mx.sym.SoftmaxOutput(data=fc3, name='softmax')shape = &#123;\"data\": (batch_size, 1, 28, 28)&#125;# mx.viz.plot_network(symbol=mlp, shape=shape)model = mx.model.FeedForward( ctx=mx.gpu(0), symbol=mlp, num_epoch=4, learning_rate=0.1)model.fit( X=train_iter, eval_data=val_iter, batch_end_callback=mx.callback.Speedometer(batch_size, 200)) 预测最后最重要的部分来了，那就是预测：predict_img = val_img[0].astype(np.float32).reshape((1, 1, 28, 28))/255.0prob = model.predict(predict_img)[0]print('prob:', prob)print('Classified as &#123;0&#125; with probability &#123;1&#125;'.format(prob.argmax(), max(prob))) 输出结果如下：Classified as 7 with probability 0.9959895014762878 说明我们的预测准确度还是非常高的啊！","categories":[],"tags":[]},{"title":"Ubuntu下编译opencv并生成python链接库详细教程-吐血编译系列","slug":"Ubuntu下编译opencv并生成python链接库详细教程-吐血编译系列","date":"2016-12-03T02:20:47.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/03/Ubuntu下编译opencv并生成python链接库详细教程-吐血编译系列/","link":"","permalink":"http://yoursite.com/2016/12/03/Ubuntu下编译opencv并生成python链接库详细教程-吐血编译系列/","excerpt":"本文将解决的是opencv这个洪水猛兽，opencv功能强大，但是无论在ubuntu下还是在windows下编译都非常麻烦，本文将编译它，并生成python调用库。哥搞了好几天才搞定，shit！","text":"本文将解决的是opencv这个洪水猛兽，opencv功能强大，但是无论在ubuntu下还是在windows下编译都非常麻烦，本文将编译它，并生成python调用库。哥搞了好几天才搞定，shit！ 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 前言opencv3.1 Ubuntu16.04 python3.5 编译完成，python下可以直接调用。先说一下，编译源码并生成python可以调用的库，检查方法是看看是否在/usr/local/lib/python3.5/dist-packages下有cv2.python-35m-x86_64-linux-gnu.so的库，如果编译生成了，说明可以在python中调用使用了，其他语言应该也差不多，但是网上的一些教程要么过时要么没有提醒你注意重要步骤甚至有些教程还是啥鸡巴扯淡的，蛋疼，我把我配置编译的过程记录一些，让后来者少走一些弯路，如果一些地方你不注意真的很容易浪费时间在各种编译错误上。首先致谢这篇英文文章，人家外国人写博客说的很清楚，不像国人写个博客妈的缺胳膊少腿。 先说几句本教程主要是教大家在ubuntu16.04 上编译python3.5版本的opencv3.1，如果你要是其他系统或者python版本步骤应该差不多，但是一定要小心修改，多尝试。整个过程容易出错以及将会导致的错误我都会粗体警示，毕竟我是踩着坑过来的。在编译python版本的opencv库之前一定要安装numpy，特此提示，后面的步骤不包含这一步 安装过程Step1 各种apt先get一下，安装需要的依赖sudo apt updatesudo apt install build-essential cmake pkg-config 其中cmake是一定要安装的，apt是最简单的安装方式，pkg-config一般系统会自带，我们不管狂安装就是 Step2 安装opencv需要的图片编码库、视频编码库等库sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-devsudo apt-get install libxvidcore-dev libx264-devsudo apt-get install libatlas-base-dev gfortran 前面两句是安装以来的编码库，包括图片和视频，最后一行是安装优化算法库atlas。 Step3 极其重要的一步，安装python开发库，如果缺少这个步骤无法生成python的调用链接sudo apt-get install python2.7-dev python3.5-dev 这里python2.7和3.5一起安装了，防止后面有人要安装2.7的版本。 Step4 下载opencv源码文件cd ~git clone https://github.com/opencv/opencv.git 从这里下载最新的opencv版本，然后我们就会在home目录下看到opencv源代码文件了。 Step5 开始编译和安装cd opencvmkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D INSTALL_PYTHON_EXAMPLES=ON -D PYTHON_EXECUTABLE=/usr/bin/python -D WITH_CUDA=OFF -D BUILD_EXAMPLES=ON .. 在这里我要解释一下，cmake后面的参数非常重要，决定了编译是否可以成功，其中比较重要的两个参数：PYTHON_EXECUTABLE WITH_CUDA,前者是告诉编译程序你的pyton解释器的路径，这个路径默认就是你在terminal输入which python弹出的路径，不管是python2.7还是3.5都是这个路径，后面这个是说你编译的时候要不要用CUDA加速，反正我是没有编译成功，所以直接放弃了，如果你有CUDA配置好了，可以参考下面这条命令：cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D INSTALL_PYTHON_EXAMPLES=ON -D PYTHON_EXECUTABLE=/usr/bin/python -D CUDA_GENERATION=Auto -D BUILD_EXAMPLES=ON .. 参数CMAKE_BUILD_TYPE CMAKE_INSTALL_PREFIX是说你的cmake的安装路径，cmake默认是安装在/usr/local下的。ok，然后enter先cmake一下。在这个过程中你可能会遇到一些问题，一般可以百度到解决方案，比如可能会遇到一个问题就是提示没有ippicv文件，说是文件校验码不对，这个时候莫慌，直接从网上搜索ippicv这个文件放到opencv/3rdparty/ippicv下即可，同时build文件夹下也复制一个（build文件夹和opencv下的目录结果一样的），然后在cmake就没有问题了。OK，接着我们makemake -j8 这个时候有问题就百度一下，都能解决，一般情况下不会遇到问题，只要你的cmake参数设置没有写错。完成之后在installsudo make install OK，我们这就编译好了opencv的库。 来玩一玩opencv千辛万苦终于编译好了，得好好玩玩这个opencv，这里哥带领大家玩一个牛逼点的例子：","categories":[],"tags":[]},{"title":"Ubuntu大手术-更换home的挂载分区获取更大空间","slug":"Ubuntu大手术-更换home的挂载分区获取更大空间","date":"2016-12-03T01:48:43.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/03/Ubuntu大手术-更换home的挂载分区获取更大空间/","link":"","permalink":"http://yoursite.com/2016/12/03/Ubuntu大手术-更换home的挂载分区获取更大空间/","excerpt":"Ubuntu系统安装时由于年少无知瞎几把设置分区，结果最后导致空间不够用，不过不用担心，本教程教你如何在不装系统的情况之下对分区进行修改","text":"Ubuntu系统安装时由于年少无知瞎几把设置分区，结果最后导致空间不够用，不过不用担心，本教程教你如何在不装系统的情况之下对分区进行修改 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 准备一个更大的分区首先当然最要紧的是准备一个更大的分区，这里我建议大家选择一个分区大小在50G以上的分区，作为开发人员是真的需要这么多空间，否则到后面又会不够用。（原则上当初安装系统的时候就应该root和home都设置为50G以上最好）更换分区大手术的思路是这样的： 将准备的新硬盘挂载到/media/home目录下 将原/home目录下的文件全部同步到/media/home目录下，这就相当于复制了一个home到新硬盘上 更改/media/home挂载为/home (可选)备份/home到/old_home以防不测 重启系统进入新home 开始备份工作接着我们打开/etc/fstab文件sudo gedit /etc/fstab 这时候你会发现这些东西：# &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;# / was on /dev/sda11 during installationUUID=48d1bdc4-b4ab-4496-880c-0298135dbbf2 / ext4 errors=remount-ro 0 1# /boot was on /dev/sda12 during installationUUID=6dbeefea-6ea4-4ab7-8a75-5a91e5e5a45c /boot ext4 defaults 0 2# /boot/efi was on /dev/sda1 during installationUUID=0A0D-7DD0 /boot/efi vfat umask=0077 0 1# /home was on /dev/sda7 during installation#UUID=5d56eef4-8f46-40ab-8ace-50122eb0bc27 /home ext4 defaults 0 2# change home mount to size80G diskUUID=b5a9ca3a-fba0-46aa-9249-4fe8c94e2f9a /home ext4 defaults 0 2# swap was on /dev/sda6 during installationUUID=563897f4-5404-466d-953f-af78250e85d0 none swap sw 0 0 大家看我加粗的一行，这是我之前的home挂在分区，下面的是新的home分区，放到你的情况就应该先把原来的home分区设置注释掉，复制一行，以免出面出错忘记了初始设置，然后我们要查看一下自己硬盘的UUID，UUID查看方式，不能出错否则挂载就错了,新开一个terminal，输入以下代码来查看：sudo blkid 这时候你就应该可以看到/dev/sda11之类的后面带着UUID，你要重新挂载的硬盘在哪个sda呢，你直接用ubuntu系统的disk软件来看，然后找到对应的UUID，复制以下，再回到刚才打开的fstab文件：# (identifier) (location, eg sda5) (format, eg ext3 or ext4) (some settings)UUID=YOURUUID /media/home ext4 defaults 0 2 回到termminal，输入：sudo mkdir /media/homesudo mount -a 然后关机重启以下，记住这里要重启以下. 开机进入Ubuntu，这时候我们就把新硬盘挂载到了/media/home路径下，不信你可以去/media下面查看，是有一个home文件夹，这个对应的物理路径就是你的新硬盘或者新分区。 OK,我们完成了挂载工作，接下来把文件同步复制到新分区sudo rsync -aXS --progress --exclude='/*/.gvfs' /home/. /media/home/. 等待文件复制完成，需要蛮久。 更换为新的home挂载修改fstab文件，到这你就差一步了：sudo /etc/fstab 把之前我们加的/media/home修改为/home# (identifier) (location, eg sda5) (format, eg ext3 or ext4) (some settings)UUID=YOURUUID /home ext4 defaults 0 2 OK,重启，进入ubuntu你会发现所有的一切还和原来一样，打开nautilus，查看以下home分区发现空间变大了！这就是linux，你可以尽情的做手术依旧保持着健壮的生命力。","categories":[],"tags":[]},{"title":"Ubuntu下设置AndroidStudio的启动快捷方式","slug":"Ubuntu下设置AndroidStudio的启动快捷方式","date":"2016-12-02T12:52:03.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/02/Ubuntu下设置AndroidStudio的启动快捷方式/","link":"","permalink":"http://yoursite.com/2016/12/02/Ubuntu下设置AndroidStudio的启动快捷方式/","excerpt":"Ubuntu下设置AndroidStudio的快捷方式","text":"Ubuntu下设置AndroidStudio的快捷方式 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu Ubuntu下设置AndroidStudio快捷方式Ubuntu下安装AndroidStudio不需要多讲，直接下载deb包，然后安装，一般安装在/opt/文件夹下，但是有个问题无法生成快捷方式，这就非常蛋疼了。不过莫慌，这个问题也好解决，就是新建一个Desktop文件，具体操作如下：sudo gedit /usr/share/applications/AndroidStudio.desktop 打开这个文件拷贝下面的配置信息进去：[Desktop Entry] Name = Studio comment= android studio Exec=/opt/android-studio/bin/studio.sh Icon=/opt/android-studio/bin/studio.png Terminal=false Type=Application 这里，opt/下就是我的AndroidStudio安装路径。保存，然后：nautilus /usr/share/applications 打开这个文件夹，找到AndroidStudio快捷方式，拖入到侧边栏即可。","categories":[],"tags":[]},{"title":"Linux下开发大神装机命令大全-从娱乐到开发","slug":"Ubuntu下开发大神玩机命令大全-从娱乐到开发","date":"2016-12-01T10:55:15.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/01/Ubuntu下开发大神玩机命令大全-从娱乐到开发/","link":"","permalink":"http://yoursite.com/2016/12/01/Ubuntu下开发大神玩机命令大全-从娱乐到开发/","excerpt":"这篇文章是一个收藏集。","text":"这篇文章是一个收藏集。 我将列举在Ubuntu下所有遇到的命令行操作。在本篇文章收集的差不多的时候我将把所有命令整合为一个.sh文件，大家装机Ubuntu后可以选择对应的版本安装配置，从而节约大量配置一些环境的时间。暂时分为三个版本：娱乐版，开发版，极客版。 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 娱乐版面向普通大众，包括一些娱乐软件的安装如QQ，迅雷，Word，ubuntu主题美化软件等的安装，开发版则包括一些开发工具的安装，比如Cmake，g++，python3.5，java等环境的搭建，当然开发版在娱乐版的基础上的扩充，为了防止臃肿所以不放在一个版本；最后极客版是集成了深度学习、Java、Python、CUDA与一体的开发环境，对机器要求较高。更新以后安装Ubuntu系统一定记得如果做开发的话home分区分至少50G！！太小了尼玛分分钟满了，root分区也至少50G，否则以后修改分区真鸡巴，麻烦 Ubuntu装机命令之-娱乐版（麻瓜版）在这个版本我们将实现以下软件的安装和配置： Longue QQ wine 最新版本 迅雷替代软件-uget 主题美化软件-unity-tweak-tools 麻瓜版预装主题-macbuntu 麻瓜版预装图标-numbic-circle 终端美化-oh my zash chrome 浏览器 搜狗拼音输入法 for linux 网易云音乐 for linux 仿mac dock栏软件plank Ubuntu装机命令之-开发版开发版我们在娱乐版的基础之上，还将安装一下： Python3.5 Java 8 Atom Markdown 写作神器 Brackets 前端神器 opencv(这个我会单独开一个版本，其中还包括Cmake，g++等的安装) …陆续补充中 Ubuntu装机命令之-极客版最后极客版在开发版的基础之上，我们还将实现一下的安装： CUDA和CUDNN（前提是有支持的显卡） Mxnet的编译和安装 Tensorflow的安装 ….陆续补充中 具体安装代码集锦（方便大家拷贝代码段） CMake的安装首先大家前往官网下载cmake包，解压到Download路径下，然后把文件夹复制到/usr/local中我们安装在这里： sudo cp -r cmake-3.7.1 /usr/localcd /usr/local/cmake-3.7.1sudo ./bootstrapsudo makesudo make installcmake --version 更新其实cmake可以直接用apt来下载和安装，apt不行的情况下在使用上面的方法，apt办法为： sudo apt install cmake OpenCV的编译和安装，生成python版本 export PYTHON3_EXECUTABLE=/usr/bin/pythonexport PYTHON_INCLUDE_DIR=/usr/include/python3.5export PYTHON_INCLUDE_DIR2=/usr/include/x86_64-linux-gnu/python3.5export PYTHON_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.5.soexport PYTHON3_NUMPY_INCLUDE_DIRS=/usr/lib/python3.5/dist-packages/numpy/core/include/ 接下来clone opencv源码，cd进入新建一个build文件夹，进入这个文件夹，执行：cmake -D CMAKE_BUILD_TYPE=bulid -D CMAKE_INSTALL_PREFIX=/usr/local -D CUDA_GENERATION=Kepler ..sudo make -j8sudo make install cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D INSTALL_PYTHON_EXAMPLES=ON -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib-3.1.0/modules -D PYTHON_EXECUTABLE=/usr/bin/python -D BUILD_EXAMPLES=ON .. 这里由于我的电脑是有GPU的，而且安装了cuda，因此后面cmake的时候有一个参数为CUDA_GENERATION,我们选择Auto，如果不加这个就是编译CPU版本，但是我这里不加会报错，建议只用CPU的可以不加这个参数。这里，make -j8参数是指定多核编译，8是你的CPU核心数。 最后我会把源代码开源到github，欢迎大家前去使用把安装过程中遇到的错误开issue提出来，也欢迎大家fork然后pull自己的安装命令进来，把我们的命令大全不断的扩充，满足更多人的需要。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"Ubuntu16.04搭建Mxnet惊天地泣鬼神完整教程,深度学习起航","slug":"Ubuntu16-04搭建Mxnet惊天地泣鬼神完整教程-深度学习起航","date":"2016-12-01T04:26:32.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/12/01/Ubuntu16-04搭建Mxnet惊天地泣鬼神完整教程-深度学习起航/","link":"","permalink":"http://yoursite.com/2016/12/01/Ubuntu16-04搭建Mxnet惊天地泣鬼神完整教程-深度学习起航/","excerpt":"本文将详细介绍Ubuntu16.04下使用CUDA和CUDNN搭建Mxnet的深度学习框架教程，其中最重要的还是CUDA和CUDNN的安装，通过本教程你可以节约很多时间，如果有什么不懂的在下面留下评论，我可以给予帮助","text":"本文将详细介绍Ubuntu16.04下使用CUDA和CUDNN搭建Mxnet的深度学习框架教程，其中最重要的还是CUDA和CUDNN的安装，通过本教程你可以节约很多时间，如果有什么不懂的在下面留下评论，我可以给予帮助 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ 前言在写这篇文章之前，我有必要吐一下草，没有错说的就是windows，JB太麻烦了，可能是我不是搞C++的吧，之前也没有搭建过caffe所以觉得非常麻烦。一直以来都是python和java，感觉就单单opencv搭建来说python下和C++相比，python就简单很多，当然也可能是因为我不熟悉visual studio的缘故，总之就整体步骤来说，我明白了一个道理，珍爱生命原理windows，如果你是搞技术的话。 Ubuntu16.04 CUDA8 CUDNN for CUDA8 Mxnet好闲话不多说让我们直接开始，如前所述，在进行我们伟大的革命事业之前，请原理windows，windows作为日常办公使用不可或缺，但是就开发来讲我拒绝它，太麻烦了，还是喜欢我们伟大的Linux，所有事情一个命令行轻松搞定，当然如果读者对Linux不熟悉的话，你可以把它当成Mac OS，毕竟Unix和Linux五八年前本是一家，慢慢你就会对Ubuntu系统的简单便捷所折服，Ubuntu已经为你准备好了一切，接下来你直接进行你伟大的创造即可。所以说我们在进行革命之前，先安装Ubuntu系统，追求个性的你不需要安装最新版本，因为我就是踩着坑过来的，新版本对中文输出法支持不好有很多莫名其妙的bug，所以还是推荐现在比较稳定的16.04.当然很多人更加追求个性，直接使用其他发行版本，比如国产的深度，Solus，Elementory OS，听老夫一言，我是踩着坑过来的，这些系统即使界面在花骚，在Ubuntu面前还是图样图森破，散木谈慕斯奈一福。哎呀这废话有点多了，相信你已经按装好了Ubuntu。接下来就是显卡。就显卡这一快我又有必要吐槽一下了，NVIDIA尼玛把显卡买那么贵真的好吗，真的不是炒作起来的吗，我有点愤青了，这让我们这些想搞点事情的年轻人情何以堪。不过不重要相信各位土豪手里都已经有了New TITAN X，如果你手里只有一块入门级的显卡，不过也没有关系，本文使用的显卡就是入门级的，丝毫不妨碍我们继续我们改变世界的伟大计划，当然以后升级是必然的，我们先吧我们的理论知识打好。接下来你要安装的就是CUDA和CUDNN。在这里我详细介绍一下，因为CUDA和CUDNN有没有安装好决定了后面Mxnet GPU版本能不能使用。 CUDA8安装教程 前往官网下载CUDA 这里我放出一个CUDA的下载链接，但是机智的我为了骗取评论数决定采取大家评论私发的方式，嘿嘿嘿～ CUDA8安装 接下来相信你已经在/Downloads文件接下有了一个文件，我们安装它 sudo dpkg -i cuda-repo-ubuntu1604-8-0-rc_8.0.27-1_amd64.deb 后面使我们下载好的文件的名字。然而我们在从apt中安装cuda：sudo apt updatesudo install cuda 最后最重要的一部，得配置环境变量，如果在这一步没有配置环境变量的话，极有可能会出错。export CUDA_HOME=/usr/local/cuda 其实这样很简单，export是手动导入变量，如果接下来安装出错的话，首先输入命令：echo $CUDA_HOME 看看是不是环境变量配置出错了。这里我们刚才install cuda的时候实际上会在/usr/local/目录下生成cuda 和cuda-8.0两个文件夹，后面这个只是让我们知道cuda的版本，因为后面cudnn要和cuda版本配套，实际使用我们只是用cuda这个文件中的库。导入了cuda环境变量之后，我们还要手动导入cuda library的环境变量：export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH 然后我们echo一下$LD_LIBRARY_PATH,看看是否导入成功。OK，进行到这里我们就安装好了CUDA了，我们在terminal里面输入：nvcc --version 看看CUDA是否安装成功，如果出来了版本说明安装好了。 CUDNN安装 接下来安装CUDNN，这是加速卷积运算的库，最好安装一下，大家要去Nvidia官网下载，注册一个Nvidia的账号，不得不说，Nvidia的官网还是很有设计感的，这里我也放出一个下载链接，因为官网下载其实有点慢，猥琐的而又机智的我希望大家评论一下然后来上链接，嘿嘿嘿CUDNN安装就是直接解压，tar zxvf cudnn8.0-linux64-amd.tar.gz 后面那个是你下载的文件的名字，接着你要复制这些文件到cuda的目录里面去：sudo cp cuda/include/* /usr/local/cuda/include/sudo cp cuda/lib64/* /usr/local/cuda/lib64/ 这个意思就是把cudnn下面的文件复制到cuda相应的文件夹之下。这样我们就安装好了吧，是的如果还报什么错就贴出来，应该这里的问题很好解决。 安装Mxnet接下来我们要安装Mxnet了，首先大家直接去github克隆最新的代码git clone --recursive https://github.com/dmlc/Mxnet 那个–recursive命令前往别忘记了，因为mxnet有一些依赖，一起下载下来，这个时候我们会在home目录下看到mxnet，我们cd进去：cd ~/mxnet 这里就是mxnet，接下来我们要编译它，编译生成我们相应的python、R、Scala库。但是编译之前我们安装一下opencv，以防万一，安装opencv很简单直接在apt中安装即可。sudo apt install opencv 如果安装不成功，可以直接百度一下，我这里就不详细说了。重点来了，接下来我们要编译mxnet，我们把mxnet/make文件夹下的config.mk文件拷贝到mxnet根目录，sudo cp ~/mxnet/make/config.mk ~/mxnet 这段代码我们在mxnet文件目录执行，然后我们sudo gedit config.mk对文件进行一个编辑。把USE_CUDA改为1，这里更改方式参考网上一些教程，同时USE_CUDNN也改为1，因为我们要安装GPU版本，所以这些都使用上，如果你是安装CPU版本的话那juice非常简单了你不需要编译直接下来官方的库即可。然后我们开始编译：make -j8 这里8指的是CPU的核心数，你可以查看一下你的CPU的核心数，我的是8核的。等待编译完成接下来重点来了，我们进入到python目录cd /usr/bin/pythonpython3 setup.py install 这里就是直接用setup工具来安装我们编译好的python mxnet库，至于为什么是python3是因为我安装了python3.5，如果你用的是2.7直接python就好了。 开始深度学习之旅一切准备就绪，开始开车！我们进入mxnet的example文件夹，来跑一个简单的mnist看看速度如何：可以说速度非常之快啊！现在我们只是开车，等一下就是真正你比吊炸天的深度学习教程了！ 感谢大家阅读我的博客，本文永久更新地址: jinfagang.coding.me 也欢迎大家积极留言，让我看到你的存在","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/深度学习/"}]},{"title":"Mac mysql 安装配置以及忘记初始密码的解决方法","slug":"Mac-mysql-安装配置以及忘记初始密码的解决方法","date":"2016-11-30T04:04:10.000Z","updated":"2017-01-12T11:47:11.000Z","comments":true,"path":"2016/11/30/Mac-mysql-安装配置以及忘记初始密码的解决方法/","link":"","permalink":"http://yoursite.com/2016/11/30/Mac-mysql-安装配置以及忘记初始密码的解决方法/","excerpt":"本文详细说明了mac下mysql的安装和配置，现在mysql出于安全考虑安装时会默认初始化一个随机密码，如果忘记了需要重置也可以从本文找到答案。","text":"本文详细说明了mac下mysql的安装和配置，现在mysql出于安全考虑安装时会默认初始化一个随机密码，如果忘记了需要重置也可以从本文找到答案。 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu Mac下mysql的安装（推荐使用dmg安装，避免不必要的麻烦）Mac下安装mysql可以直接去官网下载dmg安装包，但是速度实在是慢，如果大家需要下载链接可以在下面回复邮箱我会第一时间打给大家，当然也可以加入我们的欧曼开发者联盟QQ群：373987228，中国新一代计算机高手聚集地。好了闲话不多说我们直接看看如何安装。 首先这个mysql如果用dmg安装的话就是傻瓜一键式安装了，非常方便简单快捷。dmg安装包默认安装sql在了/usr/local文件目录下： 要重启或者停止mysql服务在设置中有： 可以说非常的简单方便快捷。好了接下来我们该干啥？安装好了对不对？我们在终端输入mysql发现并没有什么卵用啊。同志们莫慌，这是因为，你还没有吧mysql加入环境变量，怎么加也很简单。 Mysql加入环境变量我们在终端输入 vim ~/.bash_profile 我们在里面增加一行： export PATH=$PATH:/usr/local/mysql/bin 这就把mysql添加进了环境变量，后面我们就可以用这个目录下的命令了。 MySQL搭建好后忘记初始密码这是很多人遇到的问题，mysql安装时生成的密码又臭又长在终端输入根本看不到，很容易输错，而且很多时候我们搭建mysql的时候有妹子在旁边，跟妹子说话时就会忘记保存，这个时候我们就要重置密码了，在终端输入一下命令（先关闭mysql）： sudo mysqld_safe --skip-grant-tables 这里mysqld_safe的意思是让mysql进入安全模式（麻瓜也知道），后面—skip-grant-tables意思是不需要密码进入，很容易理解吧，可以说这行命令很重要，大家在必要的时候可以记住，（如果你第二次忘记密码，那么你用这个命令的时候要关闭mysqld服务，怎么关闭Google一下）接着： mysql -u root 然后就用SQL语句修改密码：UPDATE 2017.1.12 UPDATE mysql.user SET password=PASSWORD('yourpassword') WHERE User='root'; 这行命令应该改为：UPDATE mysql.user SET authentication_string=PASSWORD('root') WHERE user='root'; 因为在新版本mysql中默认保存用户名的密码表在数据库mysql下的user表中，密码保存字段变成了authentication_string OK!确定之后/c，然后exit退出，在开一个终端输入 mysql -u root -p 接着输入新密码就可以进入mysql啦~ 感谢大家阅读我的博客，本文永久更新地址: jinfagang.coding.me 也欢迎大家积极留言，让我看到你的存在","categories":[],"tags":[{"name":"web后台","slug":"web后台","permalink":"http://yoursite.com/tags/web后台/"}]},{"title":"Hexo如何在两台电脑上更新博客","slug":"Hexo如何在两台电脑上更新博客","date":"2016-11-29T13:15:10.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/11/29/Hexo如何在两台电脑上更新博客/","link":"","permalink":"http://yoursite.com/2016/11/29/Hexo如何在两台电脑上更新博客/","excerpt":"本文介绍如何用了两台电脑进行博客的更新和配置，这样你就可以在两台电脑上更新自己的博客啦！想一想就很激动啊有没有，先来演示一下，其实本人这个博客和我另外一个博客是同步更新的:jinfagang.coding.me 欢迎大家去踩踩","text":"本文介绍如何用了两台电脑进行博客的更新和配置，这样你就可以在两台电脑上更新自己的博客啦！想一想就很激动啊有没有，先来演示一下，其实本人这个博客和我另外一个博客是同步更新的:jinfagang.coding.me 欢迎大家去踩踩 两台电脑配置hexo首先废话不多说，你需要准备两台电脑，相信各位土豪都能做到。接下来你需要两个账号，什么？两个账号？我只想更新一个账号怎么办？没有关系不要慌张，我这个教程教授大家的是使用两个账号开两个博客，但是更新的内容是一样的，这样其实也没有什么不好，你以后甚至可以用两个博客展示两面的你呢。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"JavaWeb-搭建环境上传图片到后台并存储","slug":"JavaWeb-搭建环境上传图片到后台并存储","date":"2016-11-29T07:33:26.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/11/29/JavaWeb-搭建环境上传图片到后台并存储/","link":"","permalink":"http://yoursite.com/2016/11/29/JavaWeb-搭建环境上传图片到后台并存储/","excerpt":"介绍使用intelliJ idea搭建JavaWeb开发环境，以及实现简单的Servlet，从此你就可以建立自己的服务器，结合安卓或者IPhone实现任何你想通过云来完成的工作啦！","text":"介绍使用intelliJ idea搭建JavaWeb开发环境，以及实现简单的Servlet，从此你就可以建立自己的服务器，结合安卓或者IPhone实现任何你想通过云来完成的工作啦！ 本文由中南大学较为牛逼的研究生金天同学原创，欢迎转载，但是请保留这段版权信息，如果你对文章有任何疑问，欢迎微信联系我：jintianiloveu。牛逼大神一一为你解答！ intellij idea Java web环境的搭建很久以来，很多人用eclipse，什么都是eclipse，java是，安卓是，甚至连C++都有人用eclipse，然而作为一个对技术和审美有着强烈追求的男人，是不能忍受eclipse古老的界面的，这时候我们就应该使用intellij idea，地球表面以上3000米高空一下最牛逼的ide，是的你没有听错，就是它。闲话不多说，让我们看看人家idea的启动界面： 简直狂月酷炫有没有。好吧其实我知道你们很多人知道，我就不装逼了，直接说重点吧。 说先对于一个web项目来说，你的idea一定要是Ultramate版本，也就是旗舰版，不知道这个单词写错没有，大家将就看，实际上intellij全系的专业版ide都可以破解，在这里放一个破解链接，大家需要的就是获取个注册码：获取注册码通道 好了同志们要开车了，有了idea我们就要开始搭建开发环境了，请注意本次火箭即将开车。 新建一个web工程 新建工程很简单，按照向导来，在选择页面我们选择webapp 然后给工程取一个名字，接下来我们可以看到idea已经帮我新建好了一个完成的web工程。这里我们还要新建两个文件夹，结构如图所示，先不要问为什么，等一下我会告诉大家。 新建了一个classes一个lib文件夹，先建好，等一下我们再配置，建好了之后呢，我们在src文件夹下新建一个包： 包名自己取，最后我们在包下面新建一个Servlet，弹出菜单选中Servlet： 是的，你没有看错我们这就新建好了servlet，但是你还得再web.xml中添加一下Servlet的映射： 来看看生成的sevlet： 配置java文件的输出路径和lib路径 如图我们配置一下输出的路径，选择我们之前新建的classes和lib文件夹，classes和lib文件夹分别是我们java文件输出和jar依赖的文件夹。 然后切换到depencies选项卡，点击添加，添加一个jar的依赖路径： 选择jar directory: 勾选然后确定： 最后一步，我们就要配置tomcat服务器了 tomcat是什么猫我就不多说了，一个web容器，你的java web app就放在这个容器里面，web app运行依赖于我们的tomcat，那么配置的时候我们就需要点击右上角的这个地方： 来配置，在这里选择local tomcat： 只需要给tomcat服务器娶一个名字，然后点击deployment下面的添加，添加artifact依赖： 最后在旁边填写一个目录，写上工程的名字即可。哦忘了一步，在Server选项卡里面你要配置一下你的tomcat服务器，怎么配置很简单，只要configure选择你的tomcat文件夹就可以了，最外层的那个，idea自动识别。然后确定就OK。 开发小程序好搭建好了我们来个开车小程序。对了，在这个时候你可能会遇到一个问题，就是servlet识别不了server包： 这是因为我们还没有吧tomcat官方jar包放到lib文件夹下，就是我们刚才新建的那个依赖文件夹，在tomcat文件夹下的lib文件夹寻找： 这个jar包，ok现在没有报错，我们在doPost方法里面写一段代码： response.setContentType(\"text/html\");response.setCharacterEncoding(\"utf-8\");PrintWriter out = response.getWriter();out.print(\"我要毫不经意的打一个广告，是的，就是在这里，大家快使用PicBind图床神器写博客！！\"); 好的我们运行一下这个web app，如果控制台显示这样说名运行了 好，接下来激动人心的时刻到了，我们在浏览器中输入：（或者直接在弹出的浏览器中后面加上我们servlet的名字 /HelloServlet），见证奇迹的时刻到了！！！ ！！！！！ ………….好像并没有什么卵反应？我故意的，把上面那段代码拷贝到doGet方法中，在更新一下资源并重启服务器看一下： 骚年，你没有看错！！！你成功学会了使用servlet！！！ 感谢大家阅读我的博客，本文永久更新地址: jinfagang.coding.me 也欢迎大家积极留言，让我看到你的存在","categories":[],"tags":[{"name":"JavaWeb开发","slug":"JavaWeb开发","permalink":"http://yoursite.com/tags/JavaWeb开发/"}]},{"title":"PicBind--新一代图床神器","slug":"PicBind-新一代图床神器","date":"2016-11-05T12:56:22.000Z","updated":"2016-12-11T15:23:42.000Z","comments":true,"path":"2016/11/05/PicBind-新一代图床神器/","link":"","permalink":"http://yoursite.com/2016/11/05/PicBind-新一代图床神器/","excerpt":"本文介绍一个界面设计美观，自由度非常高的图床软件，写博客必备小助手—PicBind，一键拖拽上传图片，生成永久外链或Markdown格式优化外链，妈妈再也不担心你的博客图裂问题了。","text":"本文介绍一个界面设计美观，自由度非常高的图床软件，写博客必备小助手—PicBind，一键拖拽上传图片，生成永久外链或Markdown格式优化外链，妈妈再也不担心你的博客图裂问题了。 PicBind介绍PicBind是有欧曼团队打造的专注Mac下博客创作效率软件，PicBind最大的特点就是界面非常简洁，而且很美观，当然如果你真正使用它的时候你会为它的设计感染，甚至想加入欧曼团队一起创造一些产品。然而你所想的并不是没有可能，任何一个使用PicBind的用户都有可能加入欧曼创建的创业者阵营中。 PicBind外表的特点自不必多言，实际使用起来也很顺手，很自由，比起市面上其他一些图床软件来说，PicBind可以让用户设置自己的服务器，很大程度的保护了用户的隐私性以及可控性。由此可见欧曼团队在打造这款产品时充分考虑到了用户的利益。 PicBind和其他同类产品一样，采用是如丝般顺滑的使用体验，你只需要将图片拖拽到任务栏的图标，即可实现自动上传，并且会自动在粘贴板生成外链。除此之外，PicBind还设置了MarkDown格式切换选项，用户可以选中MarkDown，这样每次生成的外链就是经过MarkDown格式优化的了。 最后必须要说明的一点是，与其他图床软件软件相比，PicBind完全免费，用户自由度很高，欧曼团队在这一点上很有诚意，当然作为PicBind的忠实粉丝，为了资助欧曼团队继续开发出更多优秀的免费产品，也可以捐献一点钱给他们（PicBind的Sponsor是自愿的），只要是PicBind的Sponsor欧曼团队都将把用户加入到他们建立的创业者群中，结实一些人脉，认识认识欧曼的大大们也未尝不可~ PicBind使用 PicBind的设计非常简洁，启动App之后你甚至在Dock栏都看不到PicBind的图标，而只在状态栏有一个小“外星人的图标”，PicBind团队设计的这个图标我还是很喜欢的。 通过设置界面来设置服务器，PicBind目前仅支持七牛云服务器，七牛云最近几年发展的也比较快，各种融资，服务器也比较稳定，用七牛云图床的人也很多，所以大家可以去七牛云官方申请个账号，有免费空间和访问次数。 在写文章的时候把图片都放在桌面，需要哪张的时候就拖拽，自动生成Markdown格式的引用。 PicBind还支持上传图片历史记录，用户就可以知道自己之前上传了哪些图片了 在PicBind关于界面大家可以成为PicBind的Sponsor，给PicBind官方团队捐点钱就可以被加入到PicBind创业者交流群中，认识各种大大的好机会~ PicBind的使用感受如果你在寻找一款免费又有充分自由度的图床软件，那么PicBind绝对是你的首选，不仅有着欧曼团队的全程技术支持，而且一不小心就加入到了PicBind大大交流群中成为Sponsor，说不定哪天认识下PicBind团队CEO一起改变世界也说不定~ PicBind的未来据PicBind的开发团队，欧曼科技介绍，PicBind后期还将增加对Windows以及Linux平台的支持，我只想说，PicBind这么良心的软件应该跨平台，我也好追随PicBind的大大们一起打江山。（PS：PicBind团队也就是欧曼科技现在的核心业务是一款社交产品，我就说我咋感觉欧曼做产品有一股浓浓的社交味儿，手动偷笑，不过国内像这样的良心产品真的不多，大家且用且珍惜啊，别忘了给PicBind团队们赞助点资金，让我们的PicBind大大们去开发更多产品，创造更多的社会价值）","categories":[{"name":"个人产品","slug":"个人产品","permalink":"http://yoursite.com/categories/个人产品/"}],"tags":[{"name":"个人产品","slug":"个人产品","permalink":"http://yoursite.com/tags/个人产品/"}]},{"title":"深度学习的前景","slug":"深度学习的前景","date":"2016-10-26T05:18:00.000Z","updated":"2016-11-30T04:07:58.000Z","comments":true,"path":"2016/10/26/深度学习的前景/","link":"","permalink":"http://yoursite.com/2016/10/26/深度学习的前景/","excerpt":"本文讲述了个人对深度学习未来的看法。","text":"本文讲述了个人对深度学习未来的看法。 深度学习的未来 本文由作者金天原创，欢迎大家转载，不过请保留这段版权信息，多谢合作，如对本文有任何问题欢迎联系作者: jintianiloveu 深度学习可以说在近几年取得了非常好的发展以及社会关注度，很多公司慢慢的在把深度学习当做一种战略。而作为一个时刻在思考着未来的科技狂热分子，对于深度学习我更想表达的是，离我们真正希望的AI还差很远，纵然现在的深度学习能够解决很多问题，无论我们是否从理论上分析论证过，但是它就是work，有些时候我们就需要这样的东西，不管它多么复杂只要它能解决实际问题，那么它就是有用的，破解它也是迟早的事情。 那么深度学习的未来是什么？在哪里？ 香港科技大学一位知名教授说： 增强学习和迁移学习将是深度学习的未来。 我非常认同这位教授的观点，因为现在深度学习算法最多只能算是奠定了一个人工智能的基础，要想发展为真正的普适智能还是需要更强大的模型适应能力，以及迁移能力。","categories":[],"tags":[]}]}